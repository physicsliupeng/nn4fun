{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network for importance sampling supplemented variational inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let $\\theta \\in \\mathbb{R}^{N_d}$ the parameters, and $p(\\theta)$ the PDF of the posterior over the parameter-space. Let $q(\\theta; z)$ the inference distribution, with parameter $z$ to be trained. Let\n",
    "\\begin{equation}\n",
    "  \\hat{q}(\\theta; z, w) := \\omega (\\theta; w) q(\\theta, z),\n",
    "\\end{equation}\n",
    "where $\\omega (\\theta; w)$, mapping to $\\mathbb{R}$, is the weights of the importance sampling, with parameter $w$ to be trained.\n",
    "\n",
    "The loss-function is\n",
    "\\begin{align}\n",
    "  \\mathcal{L} (z, w)\n",
    "    & := \\textrm{KL}(\\hat{q} \\| p) \\\\\n",
    "    & = \\int \\hat{q} (\\theta)\n",
    "          \\left[ \\ln \\hat{q} (\\theta; z, w) - \\ln p (\\theta) \\right]\n",
    "        d \\theta \\\\\n",
    "    & = \\int q(\\theta) \\omega (\\theta; w)\n",
    "          \\left[ \\ln \\omega (\\theta; w) + \\ln q (\\theta; z)\n",
    "                 - \\ln p (\\theta) \\right]\n",
    "        d \\theta \\\\\n",
    "    & = \\mathbb{E}_{\\theta_s \\sim q(z)}\n",
    "          \\left\\{ \\omega (\\theta_s; w)\n",
    "            \\left[ \\ln \\omega (\\theta_s; w) + \\ln q (\\theta_s; z)\n",
    "                   - \\ln p (\\theta_s) \\right] \\right\\},\n",
    "\\end{align}\n",
    "where $s = 1, \\ldots, N_s$. Further, for $\\theta \\in \\{\\theta_1, \\ldots, \\theta_{N_s}\\} \\sim q(z)$, let\n",
    "\\begin{equation}\n",
    "  \\omega(\\theta; w) := \\textrm{softmax} \\left( \\zeta (\\theta; w) \\right) * N_s,\n",
    "\\end{equation}\n",
    "the normalization of $\\hat{q}(\\theta; z, w)$ can always be ensured:\n",
    "\\begin{align}\n",
    "  1 & = \\int \\hat{q}(\\theta; z, w) d\\theta \\\\\n",
    "    & = \\mathbb{E}_{\\theta_s \\sim q(z)} \\left[ \\omega (\\theta; w) \\right] \\\\\n",
    "    & = N_s * \\mathbb{E}_{\\theta_s \\sim q(z)}\n",
    "                \\left[ \\textrm{softmax} \\left( \\zeta (\\theta; w) \\right) \\right] \\\\\n",
    "    & = N_s * \\frac{1}{N_s}\n",
    "        \\sum_s \\textrm{softmax}_s \\left( \\zeta (\\theta; w) \\right) \\\\\n",
    "    & = N_s \\frac{1}{N_s} \\times 1.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This methods extends the representability of pure variational inference by adding a weight-function. This weight-function can be implemented by a neural network by the utility of its universality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We do not prefer a large variance of the weights, thus a penalty on this variance in the loss is called for. Thus\n",
    "\\begin{align}\n",
    "  \\mathcal{L}(z, w)\n",
    "    & \\to \\mathcal{L}(z, w; \\lambda) \\\\\n",
    "    & = \\mathbb{E}_{\\theta_s \\sim q(z)}\n",
    "          \\left\\{ \\omega (\\theta_s; w)\n",
    "            \\left[ \\ln \\omega (\\theta_s; w) + \\ln q (\\theta_s; z)\n",
    "                   - \\ln p (\\theta_s) \\right]\n",
    "            + \\lambda \\omega^2(\\theta_s; w) \\right\\},\n",
    "\\end{align}\n",
    "where $\\lambda$ is a hyper-parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The machine will automatically minimizes this loss by tuning the trainable parameters $(z, w)$, and then find a \"harmonic\" way of combining the $\\omega$ and $q$, so as to represent the target $p(\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.distributions as tfd\n",
    "from collections import namedtuple\n",
    "from uba.utils.math import softplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "LossInfo = namedtuple('LossInfo',\n",
    "    ('loc, scale, inference_dist, samples, sample_logits,'\n",
    "      'weights, log_weights, log_ps, log_qs, kl_divergence,'\n",
    "      'weight_penalty, loss'))\n",
    "\n",
    "def make_loss(n_dims, log_p, logits, logits_scale=1.0, n_samples=10):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    n_dims: Positive integer.\n",
    "    log_p: Callable from tensor of the shape `[n_dims]` to scalar.\n",
    "    logits: Callable from tensor of the shape `[n_samples, n_dims]`\n",
    "      to tensor of the shape `[n_samples]`.\n",
    "    logits_scale: Positive float.\n",
    "  Returns:\n",
    "    An instance of `LossInfo`.\n",
    "  \"\"\"\n",
    "  with tf.name_scope('Loss'):\n",
    "    with tf.name_scope('InferenceDistribution'):\n",
    "      loc = tf.get_variable('loc', [n_dims], 'float32')\n",
    "      scale = tf.get_variable('scale', [n_dims], 'float32')\n",
    "      inference_dist = tfd.Independent(\n",
    "          tfd.NormalWithSoftplusScale(loc, scale))\n",
    "    with tf.name_scope('Samples'):\n",
    "      # shape `[n_samples, n_dims]`\n",
    "      samples = inference_dist.sample(n_samples)\n",
    "    with tf.name_scope('Logits'):\n",
    "      # shape: `[n_samples]`\n",
    "      sample_logits = logits(samples)\n",
    "    with tf.name_scope('KLDivergence'):\n",
    "      # shape: `[n_samples]`\n",
    "      weights = tf.nn.softmax(sample_logits) * n_samples\n",
    "      # shape: `[n_samples]`\n",
    "      log_weights = tf.log(weights)\n",
    "      # The batch-supplement may not ensured in `log_p`,\n",
    "      # so we employ `tf.map_fn` for vectorization\n",
    "      # shape: `[n_samples]`\n",
    "      log_ps = tf.map_fn(log_p, samples)\n",
    "      # Notice `tfd.Distribution.log_prob()` is batch-supplemented,\n",
    "      # shape: `[n_samples]`\n",
    "      log_qs = inference_dist.log_prob(samples)\n",
    "      # shape: `[]`\n",
    "      kl_divergence = tf.reduce_mean(\n",
    "        weights * (log_weights + log_qs - log_ps),\n",
    "        axis=0)\n",
    "      # shape: `[]`\n",
    "      weight_penalty = logits_scale \\\n",
    "        * tf.reduce_mean(tf.square(weights - 1), axis=0)\n",
    "      # shape: `[]`\n",
    "      # loss = kl_divergence + weight_penalty\n",
    "      loss = kl_divergence * (1 + weight_penalty)\n",
    "      return LossInfo(loc, scale, inference_dist, samples, sample_logits,\n",
    "                      weights, log_weights, log_ps, log_qs, kl_divergence,\n",
    "                      weight_penalty, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### High-dimensional Gaussian distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Set up graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The target is the PDF of distribution\n",
    "$\\mathcal{N} \\left(0, \\textrm{softplus}(10)\\right)$\n",
    "on $\\mathbb{R}^{N_d}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_dims = 10000\n",
    "target_dist = tfd.Independent(\n",
    "    tfd.NormalWithSoftplusScale(loc=tf.zeros(n_dims),\n",
    "                                scale=10*tf.ones(n_dims)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def logits(samples, n_hiddens=5):\n",
    "  \"\"\"The `logits` argument of `make_loss()`.\"\"\"\n",
    "  with tf.name_scope('LogitsNeuralNetwork'):\n",
    "    # shape: `[n_samples, n_hiddens]`\n",
    "    hiddens = tf.layers.dense(samples, n_hiddens,\n",
    "                              activation=tf.nn.leaky_relu)\n",
    "    # shape: `[n_samples, 1]`\n",
    "    outputs = tf.layers.dense(hiddens, 1)\n",
    "    # shape: `[n_samples]`\n",
    "    return tf.squeeze(outputs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "loss_info = make_loss(n_dims, target_dist.log_prob, logits)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train_op = optimizer.minimize(loss_info.loss)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss (before): 51517.3\n",
      "100  |  24384.0\n",
      "200  |  23495.37890625\n",
      "300  |  22766.560546875\n",
      "400  |  22557.716796875\n",
      "500  |  24041.099609375\n",
      "600  |  22584.802734375\n",
      "700  |  22903.51171875\n",
      "800  |  22531.5234375\n",
      "900  |  22661.9609375\n",
      "1000  |  22551.880859375\n",
      "1100  |  22557.8671875\n",
      "1200  |  22270.0390625\n",
      "1300  |  21978.43359375\n",
      "1400  |  21919.84765625\n",
      "1500  |  22072.546875\n",
      "1600  |  21782.423828125\n",
      "1700  |  21661.904296875\n",
      "1800  |  21605.8984375\n",
      "1900  |  21894.2265625\n",
      "2000  |  21518.271484375\n",
      "2100  |  21500.037109375\n",
      "2200  |  21485.48046875\n",
      "2300  |  21630.26953125\n",
      "2400  |  21362.615234375\n",
      "2500  |  21342.474609375\n",
      "2600  |  21338.638671875\n",
      "2700  |  21141.94921875\n",
      "2800  |  21139.34765625\n",
      "2900  |  21098.208984375\n",
      "3000  |  20956.23828125\n",
      "3100  |  20914.453125\n",
      "3200  |  20835.708984375\n",
      "3300  |  20796.83203125\n",
      "3400  |  20684.0234375\n",
      "3500  |  20609.681640625\n",
      "3600  |  20492.130859375\n",
      "3700  |  20448.6796875\n",
      "3800  |  20375.80859375\n",
      "3900  |  20305.056640625\n",
      "4000  |  20236.634765625\n",
      "4100  |  20118.736328125\n",
      "4200  |  19991.693359375\n",
      "4300  |  19975.7578125\n",
      "4400  |  19811.955078125\n",
      "4500  |  19709.8671875\n",
      "4600  |  19622.17578125\n",
      "4700  |  19506.12109375\n",
      "4800  |  19346.8671875\n",
      "4900  |  19198.357421875\n",
      "5000  |  19088.287109375\n",
      "5100  |  18970.287109375\n",
      "5200  |  18812.283203125\n",
      "5300  |  18711.205078125\n",
      "5400  |  18531.568359375\n",
      "5500  |  18363.236328125\n",
      "5600  |  18196.345703125\n",
      "5700  |  18072.69140625\n",
      "5800  |  17918.0625\n",
      "5900  |  17798.19921875\n",
      "6000  |  17580.423828125\n",
      "6100  |  17320.505859375\n",
      "6200  |  17191.474609375\n",
      "6300  |  17001.970703125\n",
      "6400  |  16783.931640625\n",
      "6500  |  16574.03125\n",
      "6600  |  16406.890625\n",
      "6700  |  16225.3046875\n",
      "6800  |  15945.6796875\n",
      "6900  |  15746.7138671875\n",
      "7000  |  15566.662109375\n",
      "7100  |  15333.3046875\n",
      "7200  |  15073.390625\n",
      "7300  |  14915.751953125\n",
      "7400  |  14631.3974609375\n",
      "7500  |  14477.7490234375\n",
      "7600  |  14205.015625\n",
      "7700  |  13971.0615234375\n",
      "7800  |  13718.80859375\n",
      "7900  |  13498.3916015625\n",
      "8000  |  13263.330078125\n",
      "8100  |  13004.7646484375\n",
      "8200  |  12746.8828125\n",
      "8300  |  12543.71875\n",
      "8400  |  12302.55859375\n",
      "8500  |  12039.720703125\n",
      "8600  |  11861.001953125\n",
      "8700  |  11616.51953125\n",
      "8800  |  11366.822265625\n",
      "8900  |  11127.3427734375\n",
      "9000  |  10872.56640625\n",
      "9100  |  10675.5380859375\n",
      "9200  |  10410.951171875\n",
      "9300  |  10194.4326171875\n",
      "9400  |  9990.7373046875\n",
      "9500  |  9770.79296875\n",
      "9600  |  9528.0693359375\n",
      "9700  |  9303.0478515625\n",
      "9800  |  9079.2001953125\n",
      "9900  |  8862.087890625\n",
      "10000  |  8708.0322265625\n",
      "10100  |  8438.0595703125\n",
      "10200  |  8257.4580078125\n",
      "10300  |  8041.97265625\n",
      "10400  |  7872.724609375\n",
      "10500  |  7629.44873046875\n",
      "10600  |  7470.76171875\n",
      "10700  |  7284.845703125\n",
      "10800  |  7119.5712890625\n",
      "10900  |  6924.046875\n",
      "11000  |  6730.1005859375\n",
      "11100  |  6506.50927734375\n",
      "11200  |  6364.8720703125\n",
      "11300  |  6228.06982421875\n",
      "11400  |  6042.45166015625\n",
      "11500  |  5855.177734375\n",
      "11600  |  5696.31103515625\n",
      "11700  |  5541.48828125\n",
      "11800  |  5383.25927734375\n",
      "11900  |  5224.81982421875\n",
      "12000  |  5088.07421875\n",
      "12100  |  4916.861328125\n",
      "12200  |  4786.70947265625\n",
      "12300  |  4655.634765625\n",
      "12400  |  4532.17626953125\n",
      "12500  |  4409.548828125\n",
      "12600  |  4238.177734375\n",
      "12700  |  4117.5166015625\n",
      "12800  |  3994.816650390625\n",
      "12900  |  3851.751220703125\n",
      "13000  |  3724.721435546875\n",
      "13100  |  3639.66455078125\n",
      "13200  |  3503.340087890625\n",
      "13300  |  3396.96044921875\n",
      "13400  |  3282.455322265625\n",
      "13500  |  3169.965087890625\n",
      "13600  |  3056.419189453125\n",
      "13700  |  2977.841796875\n",
      "13800  |  2853.581298828125\n",
      "13900  |  2767.551513671875\n",
      "14000  |  2668.785400390625\n",
      "14100  |  2572.7783203125\n",
      "14200  |  2511.48388671875\n",
      "14300  |  2441.19775390625\n",
      "14400  |  2345.35595703125\n",
      "14500  |  2237.660400390625\n",
      "14600  |  2182.2421875\n",
      "14700  |  2103.283447265625\n",
      "14800  |  1996.537109375\n",
      "14900  |  1931.4775390625\n",
      "15000  |  1862.5313720703125\n",
      "15100  |  1763.8760986328125\n",
      "15200  |  1702.1051025390625\n",
      "15300  |  1639.780029296875\n",
      "15400  |  1577.3355712890625\n",
      "15500  |  1502.7552490234375\n",
      "15600  |  1446.9237060546875\n",
      "15700  |  1383.2242431640625\n",
      "15800  |  1329.090576171875\n",
      "15900  |  1263.1165771484375\n",
      "16000  |  1199.5390625\n",
      "16100  |  1153.5220947265625\n",
      "16200  |  1120.7681884765625\n",
      "16300  |  1052.3260498046875\n",
      "16400  |  1007.04052734375\n",
      "16500  |  954.31884765625\n",
      "16600  |  932.938232421875\n",
      "16700  |  867.8319702148438\n",
      "16800  |  839.45556640625\n",
      "16900  |  791.197265625\n",
      "17000  |  768.0721435546875\n",
      "17100  |  719.6560668945312\n",
      "17200  |  669.11865234375\n",
      "17300  |  639.7493896484375\n",
      "17400  |  610.8855590820312\n",
      "17500  |  567.5866088867188\n",
      "17600  |  527.5691528320312\n",
      "17700  |  518.4281616210938\n",
      "17800  |  482.3018798828125\n",
      "17900  |  463.9306640625\n",
      "18000  |  441.6488037109375\n",
      "18100  |  414.1590576171875\n",
      "18200  |  386.2427673339844\n",
      "18300  |  353.8907470703125\n",
      "18400  |  319.6868591308594\n",
      "18500  |  318.0928039550781\n",
      "18600  |  297.39190673828125\n",
      "18700  |  280.0654602050781\n",
      "18800  |  264.0125427246094\n",
      "18900  |  251.3677215576172\n",
      "19000  |  234.3875274658203\n",
      "19100  |  216.64501953125\n",
      "19200  |  193.7672119140625\n",
      "19300  |  186.86524963378906\n",
      "19400  |  171.0399627685547\n",
      "19500  |  167.17955017089844\n",
      "19600  |  147.0301055908203\n",
      "19700  |  141.9657745361328\n",
      "19800  |  121.15769958496094\n",
      "19900  |  118.0860595703125\n",
      "20000  |  112.2660140991211\n",
      "Loss (after): 102.542\n",
      "Weight penalty (after): 5.59375e-05\n"
     ]
    }
   ],
   "source": [
    "print('Loss (before):', sess.run(loss_info.loss))\n",
    "\n",
    "n_iters = 20000\n",
    "for step in range(1, n_iters+1):\n",
    "  sess.run(train_op)\n",
    "  \n",
    "  # The value of loss can sometimes temporally be `NaN`, and in\n",
    "  # the next `sess.run()` becomes non-`NaN` (strange!). So, we\n",
    "  # employ the following strategy:\n",
    "  loss_val = sess.run(loss_info.loss)\n",
    "  n_trials = 0\n",
    "  while np.isnan(loss_val) and n_trials < 10:\n",
    "    loss_val = sess.run(loss_info.loss)\n",
    "    n_trials += 1\n",
    "    if n_trials == 9:\n",
    "      print(sess.run([loss_info.log_weights, loss_info.log_ps,\n",
    "                      loss_info.log_qs, loss_info.kl_divergence,\n",
    "                      loss_info.weight_penalty]))\n",
    "  if n_trials == 9:\n",
    "    print('Always `NaN`, finally stopped at step {}.'.format(step))\n",
    "    break\n",
    "    \n",
    "  if step % 100 == 0:\n",
    "    print('{0}  |  {1}'.format(step, sess.run(loss_info.loss)))\n",
    "\n",
    "print('Loss (after):', sess.run(loss_info.loss))\n",
    "print('Weight penalty (after):', sess.run(loss_info.weight_penalty))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Visualize the trained results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 10000)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "log_weights = []\n",
    "for i in range(100):\n",
    "  sample_vals, log_weight_vals = sess.run(\n",
    "      [loss_info.samples, loss_info.log_weights])\n",
    "  samples += [_ for _ in sample_vals]\n",
    "  log_weights += [_ for _ in log_weight_vals]\n",
    "samples = np.array(samples)\n",
    "log_weights = np.array(log_weights)\n",
    "print(samples.shape)\n",
    "print(log_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(samples[:,0]/softplus(10), bins=50, density=True,\n",
    "         label='samples/softplus(10)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.hist(log_weights, bins=50, density=True,\n",
    "         label='log-weights')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* Conclusion: so far so good."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
