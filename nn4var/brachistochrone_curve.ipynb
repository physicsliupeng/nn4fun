{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for Variation Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brachistochrone Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, c.f. [here](https://baike.baidu.com/item/%E6%9C%80%E9%80%9F%E9%99%8D%E7%BA%BF%E9%97%AE%E9%A2%98).\n",
    "\n",
    "Another code for this problem (also in TensorFlow) can be found [herein](https://github.com/yimuw/Let-Tensor-Flow/blob/master/control/brachistochrone_curve.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a trajectory $y(x)$ for $\\forall x \\in [0, 1]$, the action (loss), as the total time spent, is given by\n",
    "$$ \\mathcal{L}[y] = \\int_0^3 d x \\frac{ \\sqrt{ 1 + {y^{\\prime}}^2 (x) } } { \\sqrt{- 2 g y(x)} } , $$\n",
    "with boundary condition\n",
    "$$ y(0) = 0 \\;, y(3) = -1 , $$\n",
    "where $g$ is the gravitational constant. Ensure that $y(x) \\le 0, \\forall x \\in [0, 1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuiruge/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Employ Monte-Carlo approximation. Let $\\{ x_i: i = 1, \\ldots, N \\} \\sim \\text{Uniform}(0, 3)$, the action with boundary condition and penalty becomes\n",
    "$$\n",
    "  \\mathcal{L}[y] = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{ \\sqrt{ 1 + {y^{\\prime}}^2 (x_i) } } { \\sqrt{-2 g y(x_i)} }\n",
    "       + \\frac{\\lambda}{2} \\sum_{ x_b \\in \\{0, 3\\} } d(y(x_b), 0), \n",
    "$$\n",
    "with some adjustable hyper-parameter $\\lambda \\in \\mathbb{R}^+$ and some pre-defined distance $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Helpers\n",
    "\n",
    "def l1_norm(x):\n",
    "    \"\"\"L1-norm.\"\"\"\n",
    "    return np.mean(np.abs(x))\n",
    "\n",
    "def flatten(nested_list):\n",
    "    \"\"\"Helper. (Recursively) flatten an arbitrarily nested list.\"\"\"\n",
    "    if nested_list == []:\n",
    "        return nested_list\n",
    "    if isinstance(nested_list[0], list):\n",
    "        return flatten(nested_list[0]) + flatten(nested_list[1:])\n",
    "    return nested_list[:1] + flatten(nested_list[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_neural_network(x, hidden_layers, output_shape, name=None):\n",
    "  \"\"\"Implement the neural network with dense hidden layers, each with\n",
    "  the same activation-function `activation`, and regularized by a\n",
    "  dropout layer with dropout-rate as the default (i.e. 0.5).\n",
    "  Args:\n",
    "    x: Tensor-like, as the input of the neural network. It's shape is\n",
    "        of `[batch_size] + x_shape`.\n",
    "    hidden_layers: List of objects of the classes in `tf.layers`.\n",
    "    output_shape: List of integers.\n",
    "  Returns:\n",
    "    The output tensor of the neural network.\n",
    "  \"\"\"\n",
    "  x = tf.convert_to_tensor(x, name='x')\n",
    "\n",
    "  with tf.name_scope(name, 'NeuralNetwork', [x]):\n",
    "    \n",
    "    # Hidden layers\n",
    "    hidden = x  # initialize.\n",
    "    for layer in hidden_layers:\n",
    "      hidden = layer(hidden)\n",
    "    \n",
    "    # Output layer\n",
    "    flatten_hidden = tf.layers.flatten(hidden)\n",
    "    output_size = sum(flatten(output_shape))\n",
    "    output = tf.layers.dense(flatten_hidden, output_size)\n",
    "    output = tf.reshape(output, [-1]+output_shape)\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action(y, grad_y, g=9.8, epsilon=1e-8, name=None):\n",
    "    \"\"\"Implements the action.\n",
    "    Args:\n",
    "      y: Tensor-like, with shape `[batch_size] + y_shape`.\n",
    "      grad_y: Tensor-like, with shape `[batch_size] + y_shape`.\n",
    "    Returns:\n",
    "      Scalar.\n",
    "    \"\"\"\n",
    "    y = tf.convert_to_tensor(y, name='y')\n",
    "    grad_y = tf.convert_to_tensor(grad_y, name='grad_y')\n",
    "    with tf.name_scope(name, 'Action', [y, grad_y]):\n",
    "      delta_height = tf.where(y < 0.0, y, tf.zeros(y.shape))\n",
    "      lagrangians = tf.truediv(\n",
    "          tf.sqrt(1.0 + tf.square(grad_y)),\n",
    "          tf.sqrt(- 2.0 * g * delta_height + epsilon))\n",
    "      return tf.reduce_mean(lagrangians)\n",
    "    \n",
    "    \n",
    "def make_distance(x, y, name=None):\n",
    "  \"\"\"Mean square distance between tensors `x` and `y`.\"\"\"\n",
    "  with tf.name_scope(name, 'MeanSquareDistance', [x, y]):\n",
    "    distance = tf.reduce_mean(tf.square(x - y))\n",
    "  return distance\n",
    "\n",
    "\n",
    "LossOps = namedtuple('LossOps',\n",
    "    'loss, y, grad_y, y_within, y_boundary, action_part, boundary_part')\n",
    "\n",
    "def make_loss(x_within, x_boundary, make_neural_network,\n",
    "              lambda_=10.0, name=None):\n",
    "  \"\"\"Implements the loss.\n",
    "  Args:\n",
    "    x_within: Tensor-like, with shape `[batch_size] + x_shape`, as the\n",
    "        non-boundary values of the input to the neural network.\n",
    "    x_boundary: Tensor-like, with shape `[n_boundaries] + x_shape`, as\n",
    "        the boundary values of the input to the neural network.\n",
    "    make_neural_network: Callable that maps `x` to the neural network\n",
    "        output.\n",
    "    lambda_: Float, as the $lambda$ in the formula of loss.\n",
    "  Returns:\n",
    "    Scalar, as the loss.\n",
    "  \"\"\"\n",
    "  x_within = tf.convert_to_tensor(x_within, name='x_within')\n",
    "  x_boundary = tf.convert_to_tensor(x_boundary, name='x_boundary')\n",
    "    \n",
    "  x = tf.concat([x_within, x_boundary], axis=0)    \n",
    "  y = make_neural_network(x)    \n",
    "\n",
    "  batch_size = x_within.get_shape().as_list()[0]\n",
    "  n_boundary = x_boundary.get_shape().as_list()[0]\n",
    "  y_within, y_boundary = tf.split(y, [batch_size, n_boundary],\n",
    "                                  axis=0)\n",
    "  grad_y = tf.gradients(y, [x])[0]\n",
    "\n",
    "  with tf.name_scope(name, 'Loss'):\n",
    "    lambda_ = tf.constant(lambda_, dtype='float32')\n",
    "    action_part = action(y, grad_y)\n",
    "    boundary = tf.constant([[0.0], [-1.0]], dtype='float32')\n",
    "    boundary_part = lambda_ * make_distance(y_boundary, boundary)\n",
    "    #loss = action_part + boundary_part\n",
    "    loss = action_part * (1.0 + boundary_part)  # for arbitrary choice.\n",
    "\n",
    "  return LossOps(loss, y, grad_y, y_within, y_boundary,\n",
    "                 action_part, boundary_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999 1.2574654 0.23390804 4.3758965 0.00036610762 0.9325102\n",
      "1999 1.24005 0.23557548 4.263918 0.0003388078 0.9193559\n",
      "2999 1.2118192 0.23848656 4.0812893 0.00030287527 0.8970489\n",
      "3999 1.1719755 0.24319413 3.819095 0.00024115361 0.86265624\n",
      "4999 1.1238164 0.2503334 3.4892786 0.00014848319 0.81415343\n",
      "5999 1.0784458 0.2600842 3.1465256 7.190925e-06 0.75425106\n",
      "6999 1.0505915 0.27081457 2.879376 0.0002184566 0.6956644\n",
      "7999 1.0414904 0.27855492 2.7389052 0.0006151478 0.65754056\n",
      "8999 1.0371915 0.28132677 2.6867857 0.0015006423 0.64465064\n",
      "9999 1.0226088 0.28200838 2.6261644 0.005192459 0.6415798\n",
      "10999 0.8799593 0.28078303 2.1339476 0.032904785 0.65020984\n",
      "11999 0.4774284 0.27415946 0.741426 0.10653598 0.74468595\n",
      "12999 0.31472152 0.29520044 0.06612823 0.29462832 0.8642909\n",
      "13999 0.32132757 0.3061746 0.04949126 0.3109526 0.86752367\n",
      "14999 0.3227609 0.3067556 0.052176084 0.30170187 0.87969714\n",
      "15999 0.29716253 0.28323102 0.049187787 0.27615932 0.89080524\n",
      "16999 0.3045095 0.29075542 0.047304623 0.24830802 0.89602256\n",
      "17999 0.31056952 0.29587245 0.049673684 0.271339 0.88695544\n",
      "18999 0.32638046 0.31173083 0.046994448 0.32232165 0.8683219\n",
      "19999 0.30552194 0.29154935 0.04792519 0.26931268 0.8789605\n",
      "20999 0.31895748 0.30669433 0.039984938 0.3194018 0.8668811\n",
      "21999 0.29325882 0.28089833 0.044003353 0.28741583 0.91705614\n",
      "22999 0.31251928 0.29402214 0.06291064 0.42640242 0.9915489\n",
      "23999 0.34150234 0.32519984 0.05013074 0.51894003 1.0374458\n",
      "24999 0.33023855 0.31417435 0.051131524 0.5071297 0.992912\n",
      "25999 0.3156243 0.2977018 0.060202833 0.40729377 0.9825402\n",
      "26999 0.30428278 0.28352258 0.073222354 0.3926662 1.0153933\n",
      "27999 0.33446744 0.31555378 0.059937965 0.54711413 0.9433523\n",
      "28999 0.3134626 0.30044848 0.04331564 0.47591132 1.0117257\n",
      "29999 0.2760432 0.2580382 0.06977658 0.3535459 1.0559571\n",
      "CPU times: user 1min 37s, sys: 20.6 s, total: 1min 57s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x_dim = 1\n",
    "n_samples = 100\n",
    "y_dim = 1\n",
    "\n",
    "with tf.name_scope('X'):\n",
    "    x_within = tf.placeholder(shape=[n_samples, x_dim], dtype='float32',\n",
    "                              name='x_within')\n",
    "    x_boundary = tf.constant([[0.0], [3.0]], dtype='float32',\n",
    "                             name='x_boundary')\n",
    "    \n",
    "with tf.name_scope('HiddenLayers'):\n",
    "    hidden_layers = []\n",
    "    for i in range(5):\n",
    "        hidden_layers += [\n",
    "            lambda x: tf.layers.dense(\n",
    "                x, 10, activation=tf.nn.sigmoid),\n",
    "            lambda x: tf.layers.dropout(x),\n",
    "        ]\n",
    "\n",
    "ops = make_loss(\n",
    "    x_within, x_boundary,\n",
    "    lambda x: make_neural_network(x, hidden_layers, [y_dim]))\n",
    "\n",
    "# For optimizing\n",
    "optimizer = tf.train.AdamOptimizer(0.01)\n",
    "#optimizer = tf.train.RMSPropOptimizer(0.01)  # an arbitrary choice.\n",
    "train_op = optimizer.minimize(ops.loss)\n",
    "\n",
    "# For logging\n",
    "tf.summary.scalar('loss', ops.loss)\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # -- Initializing\n",
    "    # For logging\n",
    "    current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    writer = tf.summary.FileWriter('../dat/logdir/'+ current_time, sess.graph)\n",
    "    # Initialize all `tf.Variable`s, explicit or implicit\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # -- Optimizing\n",
    "\n",
    "    # Parameters\n",
    "    n_iters = 3*10**4\n",
    "\n",
    "    def get_x_within_value():\n",
    "        x_within_value = np.array(\n",
    "            [[3*np.random.random()] for _ in range(n_samples)],\n",
    "            dtype='float32')\n",
    "        return x_within_value\n",
    "\n",
    "    # Iterations\n",
    "    for step in range(n_iters):\n",
    "        iter_ops = [train_op, summary_op, ops.loss, ops.y,\n",
    "                    ops.grad_y, ops.action_part, ops.boundary_part]\n",
    "        feed_dict = {x_within: get_x_within_value()}\n",
    "        result = sess.run(iter_ops, feed_dict=feed_dict)\n",
    "        _, summary, loss, y, grad_y, action_part, boundary_part = result\n",
    "        \n",
    "        # Logging\n",
    "        if (step+1) % 1000 == 0:\n",
    "            writer.add_summary(summary, step)\n",
    "            print(step, loss, action_part, boundary_part,\n",
    "                  l1_norm(grad_y), l1_norm(y))\n",
    "\n",
    "    # Return the predict-values of the trained neural network\n",
    "    x_within_value = np.linspace(0, 3, n_samples, dtype='float32')\n",
    "    x_within_value = np.expand_dims(x_within_value, axis=1)\n",
    "    y_within_value = sess.run(\n",
    "        ops.y_within,\n",
    "        feed_dict={x_within: x_within_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x121dcd630>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VdW99/HPLycTZIBABpJAAmGeBCEVFKW0ggMOaK1D\nW61P+2rtpE9t9bG2vfe2vb36eGur1g5aanuLt9b2WidUHABFpSIa5pmQAGEIkIGMkPGs548c+1Ca\nkMAh2Wf4vl+v88o5Ocuzf8ut+Z6919prm3MOERGJPjFeFyAiIt5QAIiIRCkFgIhIlFIAiIhEKQWA\niEiUUgCIiEQpBYCISJRSAIiIRCkFgIhIlIr1uoBTSU9Pd8OHD/e6DBGRsLFmzZpK51xGT9qGdAAM\nHz6coqIir8sQEQkbZra3p211CkhEJEopAEREopQCQEQkSikARESilAJARCRKKQBERKKUAkBEJEpF\nXAA0t7Xz+NslvFtc4XUpIiIhLeICIN4Xw8J3Snl+7QGvSxERCWkRFwBmxsyCQbxfWoVueC8i0rWI\nCwCAmQWDOVjbxL7q416XIiISsiIyAM4vGAzA+6VVHlciIhK6IjIARmUmMzgpnlUKABGRLkVkAHSM\nAwzWOICIyClEZAAAzCwYRHltE2XVx7wuRUQkJEVsAJw/UuMAIiKnErEBMDIjmfTkeFaVKABERDoT\nsQFgZswoGMz7pdUaBxAR6UTEBgB0TAc9VNfE3iqNA4iInCyiA2CmrgcQEelSUAFgZoPMbKmZFQd+\npnXSZpiZvWVmW81si5l9M5htno6RGUmkJycoAEREOhHsEcC9wHLn3GhgeeD1ydqAu5xzE4CZwDfM\nbEKQ2+0RM6MwP421ZTV9sTkRkbASbAAsABYFni8Crjm5gXOu3Dm3NvC8HtgG5Aa53R6bnp9GWfUx\njtQ39dUmRUTCQrABkOWcKw88PwRknaqxmQ0HzgVWn6LNbWZWZGZFFRXBr+k/Lb/jrNTavToKEBE5\nUbcBYGbLzGxzJ48FJ7ZzHXMtu5xvaWbJwLPAnc65uq7aOecWOucKnXOFGRkZp9GVzk3KTSXeF8Pa\nsqNBf5aISCSJ7a6Bc25uV++Z2WEzy3bOlZtZNnCki3ZxdPzxf8o599wZV3sGEmJ9TMpNZc1eBYCI\nyImCPQW0GLg18PxW4MWTG5iZAb8DtjnnHgpye2dken4amw7U0tzW7sXmRURCUrAB8AAwz8yKgbmB\n15hZjpktCbSZBdwCfNLM1gce84Pc7mmZnp9GS5ufLQe7PPMkIhJ1uj0FdCrOuSrg4k5+fxCYH3i+\nErBgthOsaXkfDQQf/ftzEZFoF9FXAn8kMzWRYYP6aRxAROQEUREAANPz0ijae1QLw4mIBERNAEzL\nT6Oivpn9R3WjeBERiKYA+GgcQNcDiIgAURQA44ak0D/ep3EAEZGAqAmAWF8MhcMHsbK40utSRERC\nQtQEAMDc8ZmUVjZSUtHgdSkiIp6LqgC4eHzHWnXLth72uBIREe9FVQDkDuzHhOxUlm1TAIiIRFUA\nAMydkMWavUepamj2uhQREU9FXQDMG5+F38FbO4K/14CISDiLugCYlJtKVmqCxgFEJOpFXQCYGXPH\nZ/FOcQVNrVoeWkSiV9QFAHSMAxxraWdVaZXXpYiIeCYqA+D8gsH0j/exVKeBRCSKRWUAJMb5mDM2\ngze2HKKt3e91OSIinojKAAC48pwcKhtaWL272utSREQ8EbUB8ImxmSTF+3h540GvSxER8UTUBkC/\neB/zJmTx6uZDtLTpNJCIRJ+oDQDoOA1Uc6yVv+3SCqEiEn2iOgAuGpNOamIsL23QaSARiT5RHQAJ\nsT4umzSEN7Ye1kVhIhJ1ojoAAK6akkNDcxsrtDaQiESZqA+A8wsGMzgpnpc0G0hEokzUB0CsL4Yr\nzslm2dbD1B5v9bocEZE+E/UBAPDp6UNpbvNrMFhEokpQAWBmg8xsqZkVB36mnaKtz8zWmdnLwWyz\nN0zOHcC4ISk8s2a/16WIiPSZYI8A7gWWO+dGA8sDr7vyTWBbkNvrFWbGp6cPZcO+GnYerve6HBGR\nPhFsACwAFgWeLwKu6ayRmQ0FrgCeCHJ7vebac3OJjTGeKdrndSkiIn0i2ADIcs6VB54fArK6aPcI\ncA/Q7ZoLZnabmRWZWVFFRd9NzRycnMDF4zN5ft0BWrVCqIhEgW4DwMyWmdnmTh4LTmznnHOA6+Sf\nvxI44pxb05OCnHMLnXOFzrnCjIyMnvbjrLh++jAqG1p4a/uRPt2uiIgXYrtr4Jyb29V7ZnbYzLKd\nc+Vmlg109pdzFnC1mc0HEoFUM/ujc+7mM666l8wZm0F6cgLPrNnPJROHeF2OiEivCvYU0GLg1sDz\nW4EXT27gnPuuc26oc244cBPwZij+8YeOawKum57Lm9uPUF573OtyRER6VbAB8AAwz8yKgbmB15hZ\njpktCbY4L9w8Ix+/czy9uszrUkREelVQAeCcq3LOXeycG+2cm+ucqw78/qBzbn4n7Vc4564MZpu9\nbdig/nxybCZ/+qCM5jYtECcikUtXAnfi8xcMp7Khhdc2H/K6FBGRXqMA6MRFo9IZkZ7Eovf2eF2K\niEivUQB0IibGuGVmPmvLath8oNbrckREeoUCoAvXTR9K/3gfT67a43UpIiK9QgHQhQH94rj23Fxe\nXH+QyoZmr8sRETnrFACn8IVZI2hu8/Pkqr1elyIictYpAE5hVGYy8yZk8d+r9nC8RVNCRSSyKAC6\n8ZXZBRw91soza7RKqIhEFgVANwqHD2Ja3kB++24pbVolVEQiiAKgB26bPZJ91cd5bYsuDBORyKEA\n6IF5E7IYkZ7EwndK6Vj1WkQk/CkAesAXY3z5ogI27q9l5a5Kr8sRETkrFAA9dN30XLIHJPKLN3d5\nXYqIyFmhAOihhFgfX5ldwAe7q1ldWuV1OSIiQVMAnIabzssjPTlBRwEiEhEUAKchMc7HbbNHsHJX\nJWvLjnpdjohIUBQAp+lzM/JJ6x/HL5YXe12KiEhQFACnKSkhli9dVMBbOyrYuL/G63JERM6YAuAM\n3HrBcAb2j+OhpTu9LkVE5IwpAM5AckIsX5k9khU7KlizV2MBIhKeFABn6NYL8hmcFM/DOgoQkTCl\nADhD/eNj+dqckazcVanrAkQkLCkAgnDzzHwyUxL42dKdWiNIRMKOAiAIiXE+vvGJUXywu1prBIlI\n2FEABOmm84aRO7AfP3lth44CRCSsKACClBDr4865o9l0oJZXN+t+ASISPoIKADMbZGZLzaw48DOt\ni3YDzeyvZrbdzLaZ2fnBbDfUfGraUEZnJvPTN3bormEiEjaCPQK4F1junBsNLA+87szPgdecc+OA\nKcC2ILcbUnwxxl2XjKW0opFn1+73uhwRkR4JNgAWAIsCzxcB15zcwMwGALOB3wE451qccxG3hsKl\nE7OYMmwgjywrpqm13etyRES6FWwAZDnnygPPDwFZnbQZAVQA/2Vm68zsCTNLCnK7IcfM+M6lYymv\nbeLJVXu8LkdEpFvdBoCZLTOzzZ08FpzYznVMgelsGkwsMA14zDl3LtBI16eKMLPbzKzIzIoqKipO\nrzceu2BUOh8fk8Ev39xFzbEWr8sRETmlbgPAOTfXOTepk8eLwGEzywYI/DzSyUfsB/Y751YHXv+V\njkDoansLnXOFzrnCjIyM0++Rx+69fBz1zW38ekWJ16WIiJxSsKeAFgO3Bp7fCrx4cgPn3CFgn5mN\nDfzqYmBrkNsNWeOzU7lu2lD+8Lc97D96zOtyRES6FGwAPADMM7NiYG7gNWaWY2ZLTmh3B/CUmW0E\npgL3B7ndkPbteWMwg4fe0EJxIhK6YoP5h51zVXR8oz/59weB+Se8Xg8UBrOtcJIzsB9fvHAEj79d\nwhcvHMGk3AFelyQi8k90JXAv+dqckaT1j+e+V7ZpiQgRCUkKgF6SmhjHt+aOZlVpFcu2dTY2LiLi\nLQVAL/rMeXmMykzm/iXbaGnTEhEiEloUAL0o1hfD9+ePZ3dlI398f6/X5YiI/AMFQC+bMzaDi0an\n8/Plxbo4TERCigKgl5kZ/3LFBOqbWnX/YBEJKQqAPjB2SAqfm5HPH1eXsf1QndfliIgACoA+8+15\nY0hJjOVHi7dqWqiIhAQFQB9JS4rnrkvGsqq0SncOE5GQoADoQ589L4/x2anc98o2jrfongEi4i0F\nQB/yxRg/vGoCB2qO89iKXV6XIyJRTgHQx2YUDOaaqTk8/nYpuysbvS5HRKKYAsAD37tiPAmxMfzb\ni5s1ICwinlEAeCAzJZG7Lx3Lu8WVLNmkAWER8YYCwCM3z8xnYk4q//7yFhqa27wuR0SikALAI74Y\n4z+umcSR+mZ+9sYOr8sRkSikAPDQuXlp3Dwjn0Xv7WH9vhqvyxGRKKMA8Ng9l40lMyWRe5/dSGu7\nlowWkb6jAPBYSmIcP75mEtsP1bPwnVKvyxGRKKIACAHzJmRxxeRsfr68mNKKBq/LEZEooQAIET+4\negKJsTF859mN+P26NkBEep8CIERkpiTyg6sm8uGeo/z+b7u9LkdEooACIIR8alouc8dn8uDrOyjR\nqSAR6WUKgBBiZtx/7WQS43zc/cwG2nUqSER6kQIgxGSmJvLvCyayrqxGs4JEpFcpAELQ1VNyuHzS\nEB5auoPNB2q9LkdEIlRQAWBmg8xsqZkVB36mddHuW2a2xcw2m9nTZpYYzHYj3UenggYlxfPNP6/T\nzWNEpFcEewRwL7DcOTcaWB54/Q/MLBf430Chc24S4ANuCnK7ES8tKZ6HbphKaWUj//HKVq/LEZEI\nFGwALAAWBZ4vAq7pol0s0M/MYoH+wMEgtxsVZo1K57aLCnhqdRlvbNGy0SJydgUbAFnOufLA80NA\n1skNnHMHgJ8CZUA5UOuceyPI7UaNuy4Zy8ScVO55diMHao57XY6IRJBuA8DMlgXO3Z/8WHBiO9dx\na6t/mrcYGBdYAIwAcoAkM7v5FNu7zcyKzKyooqLitDsUaeJjY/jlZ6fR1u64409rtWCciJw13QaA\nc26uc25SJ48XgcNmlg0Q+Hmkk4+YC+x2zlU451qB54ALTrG9hc65QudcYUZGxpn1KsKMSE/igesm\ns7ashp+8tt3rckQkQgR7CmgxcGvg+a3Ai520KQNmmll/MzPgYmBbkNuNOleek8Pnz8/nt+/u1niA\niJwVwQbAA8A8Myum45v+AwBmlmNmSwCcc6uBvwJrgU2BbS4McrtR6ftXjGdy7gDuemYDuysbvS5H\nRMKcdZy6D02FhYWuqKjI6zJCyr7qY1z9y5UMTk7ghW/MIjkh1uuSRCSEmNka51xhT9rqSuAwM2xQ\nf3712Wnsrmzk239Zr6WjReSMKQDC0AWj0vn+/PG8sfUwj75Z7HU5IhKmdP4gTH1h1nC2HKzjkWXF\njMxI5qopOV6XJCJhRkcAYcrMuP9Tk/jY8DTuemYDa/Ye9bokEQkzCoAwlhDr4ze3FJI9IJHbniyi\nrOqY1yWJSBhRAIS5QUnx/Nf/+hhtfscX/vABNcdavC5JRMKEAiACFGQks/CW6ew7epwv/uFDLR8t\nIj2iAIgQMwoG8+hNU1m/r4avP7VGawaJSLcUABHksknZ/Mc1k3lrRwXfeXajrhEQkVPSNNAI89kZ\neVQ1NPOzpTtJio/l3xdMpGMJJhGRf6QAiEC3f3IUDc1t/OadUhLjYvje/PEKARH5JwqACGRm3Hv5\nOJrb/Pz23d0kxvm465KxXpclIiFGARChzIx/u3ICzW3t/OLNXRjwrXljdCQgIn+nAIhgMTHGfddM\nxjl49M1dtPod91w6ViEgIoACIOLFxBj3XzuZWJ/x2IoSWtv8fP8KjQmIiAIgKsTEGD9eMInYmBie\nWLmbY63t/HjBJHwxCgGRaKYAiBJmxg+umkD/eB+/XlFC7fFWHr5hKvGxuhREJFopAKKImXHPZeMY\n2D+O+5dsp6Gpjcdunkb/eP1nIBKN9PUvCt02eyT/ed1k3i2u4DO/XU1lQ7PXJYmIBxQAUerGj+Xx\n+M3T2XGojusee489usm8SNRRAESxSyYO4akvzaTueCvXPfYe68p0UxmRaKIAiHLT89N49msXkJQQ\ny00L3+fljQe9LklE+ogCQCjISOb5r1/A5NwB3P6ndfzqrV04p5VERSKdAkAAGJycwB+/NIMFU3N4\n8PUdfPt/NtDUqhvLiEQyzf+Tv0uM8/HIjVMZlZHMz5bupLSykYW3TCcrNdHr0kSkF+gIQP6BmXHH\nxaN5/ObpFB+u56pfrGT9vhqvyxKRXhBUAJjZ9Wa2xcz8ZlZ4inaXmdkOM9tlZvcGs03pG5dNGsJz\nX7+A+NgYbnh8FX/5sMzrkkTkLAv2CGAz8Cngna4amJkP+BVwOTAB+IyZTQhyu9IHxg1J5aXbL+S8\nEYP4zrOb+P7zm2hp072GRSJFUAHgnNvmnNvRTbPzgF3OuVLnXAvwZ2BBMNuVvpOWFM+iL57HVz8+\nkqdWl3HjwlWU1x73uiwROQv6YgwgF9h3wuv9gd9JmPDFdNxh7Nefm8bOQ/Vc8ehK/rar0uuyRCRI\n3QaAmS0zs82dPHrlW7yZ3WZmRWZWVFFR0RubkDM0f3I2i++4kMFJ8dzyu9X88s1i/H5dLyASrrqd\nBuqcmxvkNg4Aw054PTTwu662txBYCFBYWKi/LiFmZEYyL3xjFt99bhM/fWMnH+45ysM3TmVQUrzX\npYlEDL/fEdMH9+voi1NAHwKjzWyEmcUDNwGL+2C70kuSEmL5+U1Tue/aSawqqeKKR99lzd5qr8sS\nCXs1x1q475Wt3PL71X1yNX6w00CvNbP9wPnAK2b2euD3OWa2BMA51wbcDrwObAP+xzm3JbiyxWtm\nxudm5P//qaK/eZ9fr9ilU0IiZ6CptZ2F75Qw+ydv8cTK3eQM6EdzH8y4s1Be86WwsNAVFRV5XYZ0\no66ple8+t4lXNpZz0eh0Hr5xKunJCV6XJRLy/H7H4g0HefD1HRyoOc6csRnce/k4xg1JPePPNLM1\nzrkur8v6h7YKADkbnHP86YMyfvTSVgb0i+PhG6Zy4eh0r8sSCVmrSqq4f8k2Nh2oZWJOKt+bP55Z\no4L/f+Z0AkBrAclZ8dEpoWl5adzx9Dpu+f1qvjJ7JHddMoY4n1YcEfnIriP1PPDqdpZtO0LOgEQe\nvnEKC6bk9smg78kUAHJWjc9OZfHts/jxy1t5/O0SVpVW8fMbpzI8Pcnr0kQ8VdnQzCPLdvL0B/vo\nH+fjO5eN4wuzhpMY5/OsJp0Ckl7zysZyvvvcRtr9jh8tmMR103Ix6/tvOSJeampt53crd/PYihKa\nWtv57Iw8vnnxaAb30jiZTgFJSLjinGym5g3kW39Zz93PbGDFjiPcd81kBvSP87o0kV7n9zteWH+A\nB1/fQXltE/MmZHHv5eMYmZHsdWl/pwCQXpU7sB9Pf3kmj79dwsNLd7Jm71F+dv0ULjgLg10ioeq9\nkkrue2UbWw7Wcc7QATx841RmFgz2uqx/olNA0mc27q/hzr+sp7SikS9dOIK7Lx3r6flPkbOt+HA9\n//fV7by5/Qi5A/txz2VjueqcnD4d4NUpIAlJ5wwdyCt3XMT9S7bxxMrdvFNcwUM3TGVS7gCvSxMJ\nypH6Jh5ZVsyfPygjKT42JAZ4e0JHAOKJFTuOcM9fN1Ld2MKdc0fz1Y+PJFbTRSXMNDa38dt3S1n4\nTiktbX4+NyOPb84d4+naWLoQTMJCzbEW/uWFzby8sZwpQwfw0+unMDorxeuyRLrV1u7nL0X7eGRZ\nMRX1zcyfPIT/c+k4RoTAdGcFgISVlzce5F9f2ExjSzvfnjeGL19UgM+Di2JEuuOc442th/nJa9sp\nqWikMD+N784fz/T8NK9L+zuNAUhYufKcHGaMGMy/vLCJB17dzqubD/Hgp89hjI4GJIR8sLua/3xt\nO2v2HmVkRhILb5nOvAlZYX1ti44AJGQ453hpYzk/XLyF+qZW7vhkx9hAfKzGBsQ728rrePD1Hby5\n/QhZqQncOXcM108fGrJjVjoCkLBkZlw9JYdZIwfzw5e28tDSnbyysZwHrpvMuXmhc4gt0WFPZSMP\nLd3JSxsPkpLQMbPnf10wnH7xoT2z53ToCEBC1tKth/nXFzZzuL6JW88fzt2XjiU5Qd9ZpHcdqDnO\nL98s5pmi/cT5YvjihcO57aKRYXMFu44AJCLMm5DFzIJBPPj6Dhat2sOrm8v5wVUTuXzSkLA+7yqh\n6UhdE796axdPf7APgJtn5vP1T4wkMyXR48p6j44AJCysKzvK95/fzNbyOj4+JoMfXT1RK4zKWXGk\nronH3i7hT6vLaPc7ri8cxh2fHEXOwH5el3ZGNA1UIlJbu58nV+3loaU7aWnz8+XZI/jGJ0bRP14H\nsnL6ymuP85u3S3n6gzLa/I7rpuVy+ydGkze4v9elBUUBIBHtSF0TD7y6nefWHSB7QCLfnT+eq87J\n1mkh6ZGyqmM8/k4Jfy3aj985rj03l9s/OYr8wZFxRKkAkKhQtKeaHyzewpaDdZybN5B/vXIC0zRb\nSLqwrbyOx98u4aUNB4mNieH6wqF89eMjGTYovL/xn0wBIFGj3e94du1+Hnx9BxX1zVx5TjZ3XzJW\n4wMCdFxbsqqkioXvlrJiRwVJ8T4+NzOfL84awZABkTm4qwCQqNPY3MZv3i7ht+/uprXdz2fOy+OO\ni0dF9AwO6VpLm59XNh3kiXd3s+VgHenJ8dx6/nA+f/7wsJnOeaYUABK1jtQ38ejyYv78wT5ifcbn\nzx/OV2YX9Nrt9yS0VDY089T7Zfxx9V4q6psZmZHEly8q4Jpzc0N+aeazRQEgUW9PZSOPLi/mhfUH\nSIzzccv5+XzpwgIyUhQEkcY5x5q9R/nv9/eyZFM5re2Oj4/J4AuzhjN7dEaf3owlFCgARAJ2HWng\n0eXFvLzxIHG+GG762DC+PLuAoWmRNfAXjWqPtfL8uv38+cN9bD9UT0pCLNdNH8rNM/MZlRk6993t\nawoAkZPsrmzk8RUlPLduP34H8ydn86ULRzBl2ECvS5PT0O53vFdSyV/X7OfVzYdoafNzztAB3PSx\nPK45N0fXhNCHAWBm1wM/BMYD5znn/umvtZkNA54EsgAHLHTO/bwnn68AkLPtYM1x/vDeHp5eXUZ9\ncxvT89P4/Pn5XDZpCAmx0XGOOBxtP1THC+sO8sK6AxyqayI1MZYFU3O56bxhTMzRLUVP1JcBMB7w\nA78B7u4iALKBbOfcWjNLAdYA1zjntnb3+QoA6S0NzW385cN9/PeqPeypOsbgpHhu+NgwbigcFhJ3\ndZKOo7Ylm8pZvP4gOw7X44sxZo9O59PTh3Hx+MyoGdQ9XX1+CsjMVtBFAHTS9kXgl865pd21VQBI\nb/P7HSt3VfLkqr28uf0wfgfnDR/EpwuHctmkIaQmRvaUwVDinGPH4XqWbjnMks2H2FZeB8D0/DQW\nTM1h/uRs0jWbq1shGwBmNhx4B5jknKvr7nMVANKXDtc18eza/TxTtJ/dlY3Ex8Zw8bhMrp6Sw5yx\nmRG1DnyoaG5r54Pd1by1vYKl2w6xr/o4AIX5aVw+OZvLJg0hN0wXZfPKWQ0AM1sGDOnkre87514M\ntFlBNwFgZsnA28B9zrnnTtHuNuA2gLy8vOl79+7trg8iZ5VzjrVlNby04SAvbzxIZUMLiXExzBmT\nyaWTspgzJpO0pHivywxLzjl2HWlg5a5KVhZX8l5JFcdb24mPjWHWyMHMmzCEueMzyUzVBXxnKuSO\nAMwsDngZeN0591BPP1dHAOK1tnY/q3dX89rmQ7y+5RBH6puJMTg3L405YzK4cHQ6k3MHhOztAb3m\n9ztKKhpYvbu641FaxZH6ZgDyBvVnztgM5ozNYGbBYM3gOUtCKgCsY4nGRUC1c+7O0/lcBYCEEr/f\nsWF/DSt2VPDWjiNs3F8LQEpCLDMKBnHeiEFMzx/EpNzUqJ1RVN3YwqYDtawvq2HdvqOsK6uh9ngr\nAJkpCcwoGMyskYOZNSo94hZhCxV9OQvoWuAXQAZQA6x3zl1qZjnAE865+WZ2IfAusImOGUMA33PO\nLenu8xUAEsqqGppZVVrFeyVVrCqpYndlIwDxsTFMzEllytCBTM4dwMTcVArSkyPq5vZt7X7Kqo+x\n83A9W8vr2V5ex5aDdRyo6TiHbwZjMlM4N28g0/LSmFEwiLxB/bVkdx/QhWAiHqiob2bN3qOs2VvN\nhn21bD5Yy7GWdgDifMbIjGRGZ6VQkJ7EyMxkRgxOYtigfgzoFxeSfxhb2/0cqm1i/9HjlFU3sqfq\nGHsqGymtaGR3ZSMt7R3f52IMRqQnMT47lXOGDmBy7kAm5aaSohlUnlAAiISA9sD5723ldWw/1PEt\neVdFA/uPHufE/+1SEmPJHdiPIQMSyR6QSEZKIunJ8aQnJ5DWP57UfrEM6BdHar84+sf5zni8oa3d\nT2NzOw0tbdQea6X2eMejqrGZqoYWqhqaOVzXzKG6Jg4HHv4T6ozzGcMG9acgPYlRmSmMykxmTFYy\nY7JSNCc/hOim8CIhwBdjjMlKYUxWCgtO+H1Tazt7qhrZW3WMfdXHKKs+xsGaJg7VHWfT/lqqj7Vw\nqu9l8bEx9IvzER8bQ7wvhjifEWOGGZgZfr+jze9o9zua2/w0t7XT3Oanpc3f9YcCqYmxZKUmkpWa\nSMHIweQO7MfQtH4MTevPsLT+5AxM1GB3hFEAiPSxxDgf44akMm5Iaqfvt7X7OXqs45t5dUMLdU0d\n39Trm9o41tJOY0sbTS3ttLT7aWlztLb78TuHo2OapS8mBp+BLyaGhLgYEmJjSIj1kRTvo39CLMkJ\nPlIT4/5+VJGenMCgpPiIGqOQnlEAiISYWF8MGSkJWrpaep0iX0QkSikARESilAJARCRKKQBERKKU\nAkBEJEopAEREopQCQEQkSikARESiVEivBWRmFcCZ3hEmHag8i+V4KVL6Ein9APUlFEVKPyC4vuQ7\n5zJ60jCkAyAYZlbU0wWRQl2k9CVS+gHqSyiKlH5A3/VFp4BERKKUAkBEJEpFcgAs9LqAsyhS+hIp\n/QD1JRRW5/P4AAADFklEQVRFSj+gj/oSsWMAIiJyapF8BCAiIqcQ1gFgZpeZ2Q4z22Vm93byvpnZ\no4H3N5rZNC/q7Ike9GWOmdWa2frA49+8qLM7ZvZ7MztiZpu7eD+c9kl3fQmXfTLMzN4ys61mtsXM\nvtlJm7DYLz3sS7jsl0Qz+8DMNgT68qNO2vTufnHOheUD8AElQAEQD2wAJpzUZj7wKmDATGC113UH\n0Zc5wMte19qDvswGpgGbu3g/LPZJD/sSLvskG5gWeJ4C7Azj/1d60pdw2S8GJAeexwGrgZl9uV/C\n+QjgPGCXc67UOdcC/Bn+4darBF4/6Tq8Dww0s+y+LrQHetKXsOCceweoPkWTcNknPelLWHDOlTvn\n1gae1wPbgNyTmoXFfulhX8JC4N91Q+BlXOBx8qBsr+6XcA6AXGDfCa/388//IfSkTSjoaZ0XBA4D\nXzWziX1T2lkXLvukp8Jqn5jZcOBcOr5tnijs9ssp+gJhsl/MzGdm64EjwFLnXJ/uF90TOHysBfKc\ncw1mNh94ARjtcU3RLqz2iZklA88Cdzrn6ryuJxjd9CVs9otzrh2YamYDgefNbJJzrtMxp94QzkcA\nB4BhJ7weGvjd6bYJBd3W6Zyr++hw0Tm3BIgzs/S+K/GsCZd90q1w2idmFkfHH8ynnHPPddIkbPZL\nd30Jp/3yEedcDfAWcNlJb/XqfgnnAPgQGG1mI8wsHrgJWHxSm8XA5wMj6TOBWudceV8X2gPd9sXM\nhpiZBZ6fR8e+q+rzSoMXLvukW+GyTwI1/g7Y5px7qItmYbFfetKXMNovGYFv/phZP2AesP2kZr26\nX8L2FJBzrs3Mbgdep2MWze+dc1vM7KuB9x8HltAxir4LOAZ8wat6T6WHffk08DUzawOOAze5wDSB\nUGJmT9MxCyPdzPYDP6BjcCus9gn0qC9hsU+AWcAtwKbA+WaA7wF5EHb7pSd9CZf9kg0sMjMfHSH1\nP865l/vyb5iuBBYRiVLhfApIRESCoAAQEYlSCgARkSilABARiVIKABGRKKUAEBGJUgoAEZEopQAQ\nEYlS/w9LPBd/6xjiaQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12121f1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization\n",
    "plt.plot(x_within_value, y_within_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "  * Compare with analytic result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
