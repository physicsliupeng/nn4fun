{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for Variation Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brachistochrone Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, c.f. [here](https://baike.baidu.com/item/%E6%9C%80%E9%80%9F%E9%99%8D%E7%BA%BF%E9%97%AE%E9%A2%98).\n",
    "\n",
    "Another code for this problem (also in TensorFlow) can be found [herein](https://github.com/yimuw/Let-Tensor-Flow/blob/master/control/brachistochrone_curve.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a trajectory $y(x)$ for $\\forall x \\in [x_0, x_1]$, the action (loss), as the total time spent, is given by\n",
    "\\begin{equation}\n",
    "  \\mathcal{L}[y] = \\int_{x_0}^{x_1} d x \\frac{ \\sqrt{ 1 + {y^{\\prime}}^2 (x) } } { \\sqrt{ 2 g \\left( y_0 - y(x) \\right) } },\n",
    "\\end{equation}\n",
    "with boundary condition\n",
    "$$ y(x_0) = y_0 \\;, y(x_1) = y_1 , $$\n",
    "where $g$ is the gravitational constant and $y_0 > y_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shuiruge/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "import random as rn\n",
    "import os\n",
    "\n",
    "# Global parameters\n",
    "_SEED = 42\n",
    "_EPSILON = 1e-8\n",
    "\n",
    "# For reproducibility\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(_SEED)\n",
    "rn.seed(_SEED)\n",
    "tf.set_random_seed(_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Employ Monte-Carlo approximation. Let $\\{ x_i: i = 1, \\ldots, N \\} \\sim \\text{Uniform}(x_0, x_1)$, the action with boundary condition and penalty becomes\n",
    "\\begin{equation}\n",
    "  \\mathcal{L}[y] = \\frac{1}{N} \\sum_{i=1}^{N} \n",
    "                      \\frac{ \\sqrt{ 1 + {y^{\\prime}}^2 (x_i) } }{ \\sqrt{ 2 g \\left( y_0 - y(x_i) \\right) } }\n",
    "                 + \\frac{1}{2} \\sum_{ x_b \\in \\{x_0, x_1\\} } d(y(x_b)), \n",
    "\\end{equation}\n",
    "with some pre-defined distance $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_neural_network(x, hidden_layers, output_shape, name=None):\n",
    "  \"\"\"Implement the generic neural network with the dense linear output\n",
    "  layer.\n",
    "  Args:\n",
    "    x: Tensor-like, as the input of the neural network. It's shape is\n",
    "        of `[batch_size] + x_shape`.\n",
    "    hidden_layers: List of objects of the classes in `tf.layers`.\n",
    "    output_shape: List of integers.\n",
    "  Returns:\n",
    "    The output tensor of the neural network.\n",
    "  \"\"\"\n",
    "  with tf.name_scope(name, 'NeuralNetwork', [x]):\n",
    "    x = tf.convert_to_tensor(x)\n",
    "    \n",
    "    # Hidden layers\n",
    "    hidden = x  # initialize.\n",
    "    for layer in hidden_layers:\n",
    "      hidden = layer(hidden)\n",
    "    \n",
    "    # Output layer\n",
    "    flatten_hidden = tf.layers.flatten(hidden)\n",
    "    output_size = sum(flatten(output_shape))\n",
    "    output = tf.layers.dense(flatten_hidden, output_size)\n",
    "    output = tf.reshape(output, [-1]+output_shape)\n",
    "\n",
    "  return output\n",
    "\n",
    "\n",
    "def flatten(nested_list):\n",
    "    \"\"\"Helper. (Recursively) flatten an arbitrarily nested list.\"\"\"\n",
    "    if nested_list == []:\n",
    "        return nested_list\n",
    "    if isinstance(nested_list[0], list):\n",
    "        return flatten(nested_list[0]) + flatten(nested_list[1:])\n",
    "    return nested_list[:1] + flatten(nested_list[1:])\n",
    "\n",
    "\n",
    "def make_action(y_bulk, grad_y_bulk, y_0, g=9.8, epsilon=_EPSILON, name=None):\n",
    "    \"\"\"Implements the action in Monte-Carlo integral.\n",
    "    \n",
    "    The action is a Monte-Carlo integral IN THE BULK.\n",
    "    \n",
    "    Args:\n",
    "      y: Tensor-like, with shape `[batch_size] + y_shape`.\n",
    "      grad_y: Tensor-like, with shape `[batch_size] + y_shape`.\n",
    "      y_0: Tensor-like, with shape `y_shape`.\n",
    "      g: Scalar-like, as the gravitational constant, optional.\n",
    "      epsilon: Scalar-like, for numerical stability, optional.\n",
    "    Returns:\n",
    "      Scalar.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(name, 'Action', [y_bulk, grad_y_bulk, y_0]):\n",
    "      y_bulk = tf.convert_to_tensor(y_bulk)\n",
    "      grad_y_bulk = tf.convert_to_tensor(grad_y_bulk)\n",
    "      y_0 = tf.convert_to_tensor(y_0)\n",
    "      # Add `batch_size`-dimension\n",
    "      y_0 = tf.expand_dims(y_0, axis=0)\n",
    "    \n",
    "      with tf.name_scope('DeltaHeight'):\n",
    "        delta_y = y_0 - y_bulk\n",
    "        # Clip `delta_y` so as to keep it positive\n",
    "        delta_y = tf.where(delta_y > 0.0, delta_y, tf.zeros_like(delta_y))\n",
    "        \n",
    "      with tf.name_scope('Lagrangian'):\n",
    "        lagrangians = tf.truediv(\n",
    "            tf.sqrt(1.0 + grad_y_bulk**2),\n",
    "            tf.sqrt(2.0 * g * delta_y) + epsilon)\n",
    "        \n",
    "      action = tf.reduce_mean(lagrangians)\n",
    "      return action\n",
    "\n",
    "\n",
    "def make_boundary(y_boundary, target_y_boundary, n=4, lambda_=50.0, name=None):\n",
    "  \"\"\"Make the boundary term, vanishing of which makes the fitting of boundary.\n",
    "  \n",
    "  $ b(y, y_b) := \\lambda * \\norm{y - y_b}_n $\n",
    "  \n",
    "  Args:\n",
    "    y_boundary: Tensor-like, with the shape `[n_boundary] + y_shape`, as the\n",
    "        boundary given by the neural network, as the $y$.\n",
    "    target_y_boundary: Tensor-like, with the shape `[n_boundary] + y_shape`,\n",
    "        as the target boundary to fit, as the $y_b$.\n",
    "    n: Positive integer, employ L-`n` norm.\n",
    "    lambda: Positive float.\n",
    "  Returns:\n",
    "    Scalar.\n",
    "  \"\"\"\n",
    "  with tf.name_scope(name, 'Boundary', [y_boundary, target_y_boundary]):\n",
    "    y_boundary = tf.convert_to_tensor(y_boundary)\n",
    "    target_y_boundary = tf.convert_to_tensor(target_y_boundary)\n",
    "    # `delta` shall be vanishing\n",
    "    delta = (y_boundary - target_y_boundary)\n",
    "    boundary = lambda_ * l_n_norm(delta, n)\n",
    "    return boundary\n",
    "\n",
    "\n",
    "def l_n_norm(x, n, name=None):\n",
    "  \"\"\"L-`n` norm of tensor `x`.\"\"\"\n",
    "  with tf.name_scope(name, 'L{}_Norm'.format(n), [x]):\n",
    "    x = tf.convert_to_tensor(x)\n",
    "    norm = tf.reduce_mean(x**n)\n",
    "    return norm\n",
    "\n",
    "\n",
    "ResultOps = namedtuple('ResultOps',\n",
    "    'loss, grad_y_bulk, y_bulk, y_boundary, action, boundary')\n",
    "\n",
    "\n",
    "def make_loss(x_bulk, x_boundary, target_y_boundary, make_y,\n",
    "              name=None):\n",
    "  \"\"\"Implements the loss.\n",
    "  \n",
    "  It is found that `loss = action * (1 + boundary)` is much more numerically\n",
    "  stable and performs much better than `loss = action + boundary`.\n",
    "  \n",
    "  XXX: Why so?\n",
    "  \n",
    "  Args:\n",
    "    x_bulk: Tensor-like, with shape `[batch_size] + x_shape`, as the\n",
    "        non-boundary values of the input to the neural network.\n",
    "    x_boundary: Tensor-like, with shape `[n_boundaries] + x_shape`, as\n",
    "        the boundary values of the input to the neural network.\n",
    "    target_y_boundary: Tensor-like, with the shape `[n_boundary] + y_shape`,\n",
    "        as the target boundary to fit.\n",
    "    make_y: Callable that maps `x` to the neural network output.\n",
    "  Returns:\n",
    "    Scalar.\n",
    "  \"\"\"\n",
    "  with tf.name_scope(name, 'Loss',\n",
    "        [x_bulk, x_boundary, target_y_boundary]):\n",
    "    x_bulk = tf.convert_to_tensor(x_bulk)\n",
    "    x_boundary = tf.convert_to_tensor(x_boundary)\n",
    "    target_y_boundary = tf.convert_to_tensor(target_y_boundary)\n",
    "    \n",
    "    x = tf.concat([x_bulk, x_boundary], axis=0)\n",
    "    y = make_y(x)\n",
    "\n",
    "    batch_size = x_bulk.get_shape().as_list()[0]\n",
    "    n_boundary = x_boundary.get_shape().as_list()[0]\n",
    "    y_bulk, y_boundary = tf.split(y, [batch_size, n_boundary],\n",
    "                                  axis=0)\n",
    "    grad_y_bulk = tf.gradients(y_bulk, [x_bulk])[0]\n",
    "    y_0 = tf.unstack(target_y_boundary, axis=0)[0]\n",
    "\n",
    "    action = make_action(y_bulk, grad_y_bulk, y_0)\n",
    "    boundary = make_boundary(y_boundary, target_y_boundary)\n",
    "    #loss = action * (1 + boundary)\n",
    "    loss = action + boundary\n",
    "\n",
    "  return ResultOps(loss, grad_y_bulk, y_bulk, y_boundary, action, boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frame(X, y, pause):\n",
    "    \"\"\"Helper. For dynamical plot.\n",
    "    Args:\n",
    "        X: Array-like.\n",
    "        y: Array-like.\n",
    "        pause: Float or `None`.\n",
    "    \"\"\"\n",
    "    plt.plot(X, y)\n",
    "    plt.draw()\n",
    "    plt.axis('equal')\n",
    "    if pause:\n",
    "        plt.pause(0.01)\n",
    "        plt.clf()\n",
    "        \n",
    "\n",
    "def l1_norm(x):\n",
    "    \"\"\"Helper. L1-norm.\"\"\"\n",
    "    return np.mean(np.abs(x))\n",
    "\n",
    "\n",
    "def test():\n",
    "\n",
    "    # -- Build graph\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    x_dim = 1\n",
    "    n_samples = 1000\n",
    "    y_dim = 1\n",
    "\n",
    "    x_bulk = tf.placeholder(shape=[n_samples, x_dim], dtype='float32',\n",
    "                            name='x_bulk')\n",
    "    x_boundary = np.array([[0.0], [3.0]], dtype='float32')\n",
    "    target_y_boundary = np.array([[0.0], [-1.0]], dtype='float32')\n",
    "\n",
    "    hidden_layers = []\n",
    "    for i in range(5):\n",
    "        hidden_layers += [\n",
    "            lambda x: tf.layers.dense(\n",
    "                x, 10, activation=tf.nn.sigmoid),\n",
    "            lambda x: tf.layers.dropout(x),\n",
    "        ]\n",
    "            \n",
    "    def make_y(x):\n",
    "        return make_neural_network(x, hidden_layers, [y_dim])\n",
    "\n",
    "    ops = make_loss(x_bulk, x_boundary, target_y_boundary, make_y)\n",
    "\n",
    "    # For optimizing\n",
    "    optimizer = tf.train.AdamOptimizer(0.01)\n",
    "    train_op = optimizer.minimize(ops.loss)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Initialize all `tf.Variable`s, explicit or implicit\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # -- Optimizing\n",
    "\n",
    "        # Parameters\n",
    "        n_iters = 4*10**4\n",
    "\n",
    "        def get_x_bulk_value():\n",
    "            x_bulk_value = -np.random.uniform(\n",
    "                -x_boundary[1,0], -x_boundary[0,0], size=[n_samples, 1])\n",
    "            x_bulk_value = x_bulk_value.astype('float32')\n",
    "            x_bulk_value = np.sort(x_bulk_value, axis=0)\n",
    "            return x_bulk_value\n",
    "\n",
    "        # Iterations\n",
    "        for i in range(n_iters):\n",
    "            step = i + 1\n",
    "            iter_ops = [train_op, ops.loss, ops.y_bulk, ops.grad_y_bulk,\n",
    "                        ops.action, ops.boundary]\n",
    "            x_bulk_value = get_x_bulk_value()\n",
    "            result = sess.run(iter_ops, feed_dict={x_bulk: x_bulk_value})\n",
    "            _, loss, y_bulk, grad_y_bulk, action, boundary = result\n",
    "\n",
    "            if step % 1000 == 0:\n",
    "                #plot_frame(x_bulk_value, y_bulk, pause=0.01)\n",
    "                print(step, loss, action, boundary)\n",
    "\n",
    "            # For debugging\n",
    "            if np.isnan(loss):\n",
    "                print(step, loss, action, boundary,\n",
    "                      grad_y_bulk, x_bulk_value, y_bulk)\n",
    "                plot_frame(x_bulk_value, y_bulk, pause=None)\n",
    "                break\n",
    "                \n",
    "        # Return the predict-values of the trained neural network\n",
    "        x_bulk_value = np.linspace(x_boundary[0,0], x_boundary[1,0],\n",
    "                                   n_samples, dtype='float32')\n",
    "        x_bulk_value = np.expand_dims(x_bulk_value, axis=1)\n",
    "        y_bulk_value = sess.run(\n",
    "            ops.y_bulk,\n",
    "            feed_dict={x_bulk: x_bulk_value})\n",
    "\n",
    "        # Visualization\n",
    "        plt.plot(x_bulk_value, y_bulk_value)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.3062894 0.2982517 0.008037702\n",
      "2000 0.28698048 0.28223798 0.0047425097\n",
      "3000 0.2986106 0.29207316 0.0065374486\n",
      "4000 0.29660526 0.28866437 0.00794089\n",
      "5000 0.29562706 0.28757232 0.008054738\n",
      "6000 0.29988283 0.29189312 0.007989718\n",
      "7000 0.2977259 0.292029 0.005696889\n",
      "8000 0.29993576 0.29529583 0.0046399287\n",
      "9000 0.30054876 0.29497966 0.0055690957\n",
      "10000 0.2864439 0.27945673 0.0069871554\n",
      "11000 0.2986378 0.29109237 0.0075454284\n",
      "12000 0.29648757 0.29079804 0.0056895236\n",
      "13000 0.2972462 0.29063624 0.0066099376\n",
      "14000 0.2907791 0.28416646 0.006612654\n",
      "15000 0.30585927 0.29708302 0.008776239\n",
      "16000 0.28686714 0.2781064 0.008760739\n",
      "17000 0.29752275 0.28941768 0.008105081\n",
      "18000 0.2885112 0.28357807 0.004933115\n",
      "19000 0.29508662 0.2894581 0.0056285253\n",
      "20000 0.293449 0.28943753 0.00401149\n",
      "21000 0.28974286 0.28167334 0.008069514\n",
      "22000 0.29015493 0.28430834 0.005846587\n",
      "23000 0.28845146 0.28046474 0.007986736\n",
      "24000 0.28723776 0.28153458 0.00570319\n",
      "25000 0.29283324 0.285355 0.007478246\n",
      "26000 0.29072788 0.28298303 0.0077448594\n",
      "27000 0.29610246 0.28907806 0.007024402\n",
      "28000 0.29290786 0.28739822 0.0055096406\n",
      "29000 0.28201452 0.2757016 0.0063129193\n",
      "30000 0.28585923 0.28002185 0.0058373776\n",
      "31000 0.3054113 0.29772288 0.007688426\n",
      "32000 0.29850525 0.29228997 0.0062152757\n",
      "33000 0.2998631 0.29292342 0.0069396766\n",
      "34000 0.30255538 0.29618332 0.0063720676\n",
      "35000 0.29730597 0.29094756 0.006358421\n",
      "36000 0.284854 0.2776277 0.0072262804\n",
      "37000 0.29299358 0.28656828 0.006425277\n",
      "38000 0.28864142 0.28112113 0.0075202812\n",
      "39000 0.29772887 0.29143313 0.0062957536\n",
      "40000 0.28715652 0.2783967 0.008759816\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEQlTCgARkTClABARCVMKABGRMPX/AVOB9O2f93sYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e3980b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 46s, sys: 30.5 s, total: 4min 16s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "  * Compare with analytic result.\n",
    "  * Coherent the numerical stability at boundary and the penalty to the boundary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
