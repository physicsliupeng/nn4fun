{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for Variation Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brachistochrone Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, c.f. [here](https://baike.baidu.com/item/%E6%9C%80%E9%80%9F%E9%99%8D%E7%BA%BF%E9%97%AE%E9%A2%98).\n",
    "\n",
    "Another code for this problem (also in TensorFlow) can be found [herein](https://github.com/yimuw/Let-Tensor-Flow/blob/master/control/brachistochrone_curve.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a trajectory $y(x)$ for $\\forall x \\in [x_0, x_1]$, the action (loss), as the total time spent, is given by\n",
    "\\begin{equation}\n",
    "  \\mathcal{L}[y] = \\int_{x_0}^{x_1} d x \\frac{ \\sqrt{ 1 + {y^{\\prime}}^2 (x) } } { \\sqrt{ 2 g \\left( y_0 - y(x) \\right) } },\n",
    "\\end{equation}\n",
    "with boundary condition\n",
    "$$ y(x_0) = y_0 \\;, y(x_1) = y_1 , $$\n",
    "where $g$ is the gravitational constant and $y_0 > y_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "import random as rn\n",
    "import os\n",
    "\n",
    "# Global parameters\n",
    "_SEED = 42\n",
    "_EPSILON = 1e-8\n",
    "\n",
    "# For reproducibility\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(_SEED)\n",
    "rn.seed(_SEED)\n",
    "tf.set_random_seed(_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Employ Monte-Carlo approximation. Let $\\{ x_i: i = 1, \\ldots, N \\} \\sim \\text{Uniform}(x_0, x_1)$, the action with boundary condition and penalty becomes\n",
    "\\begin{equation}\n",
    "  \\mathcal{L}[y] = \\frac{1}{N} \\sum_{i=1}^{N} \n",
    "                      \\frac{ \\sqrt{ 1 + {y^{\\prime}}^2 (x_i) } }{ \\sqrt{ 2 g \\left( y_0 - y(x_i) \\right) } }\n",
    "                 + \\frac{1}{2} \\sum_{ x_b \\in \\{x_0, x_1\\} } d(y(x_b)), \n",
    "\\end{equation}\n",
    "with some pre-defined distance $d$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_neural_network(x, hidden_layers, output_shape, name=None):\n",
    "  \"\"\"Implement the generic neural network with the dense linear output\n",
    "  layer.\n",
    "  Args:\n",
    "    x: Tensor-like, as the input of the neural network. It's shape is\n",
    "        of `[batch_size] + x_shape`.\n",
    "    hidden_layers: List of objects of the classes in `tf.layers`.\n",
    "    output_shape: List of integers.\n",
    "  Returns:\n",
    "    The output tensor of the neural network.\n",
    "  \"\"\"\n",
    "  with tf.name_scope(name, 'NeuralNetwork', [x]):\n",
    "    x = tf.convert_to_tensor(x)\n",
    "    \n",
    "    # Hidden layers\n",
    "    hidden = x  # initialize.\n",
    "    for layer in hidden_layers:\n",
    "      hidden = layer(hidden)\n",
    "    \n",
    "    # Output layer\n",
    "    flatten_hidden = tf.layers.flatten(hidden)\n",
    "    output_size = sum(flatten(output_shape))\n",
    "    output = tf.layers.dense(flatten_hidden, output_size)\n",
    "    output = tf.reshape(output, [-1]+output_shape)\n",
    "\n",
    "  return output\n",
    "\n",
    "\n",
    "def flatten(nested_list):\n",
    "    \"\"\"Helper. (Recursively) flatten an arbitrarily nested list.\"\"\"\n",
    "    if nested_list == []:\n",
    "        return nested_list\n",
    "    if isinstance(nested_list[0], list):\n",
    "        return flatten(nested_list[0]) + flatten(nested_list[1:])\n",
    "    return nested_list[:1] + flatten(nested_list[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_action(y_bulk, grad_y_bulk, y_0, g=9.8, epsilon=_EPSILON, name=None):\n",
    "    \"\"\"Implements the action in Monte-Carlo integral.\n",
    "    \n",
    "    The action is a Monte-Carlo integral IN THE BULK.\n",
    "    \n",
    "    Args:\n",
    "      y: Tensor-like, with shape `[batch_size] + y_shape`.\n",
    "      grad_y: Tensor-like, with shape `[batch_size] + y_shape`.\n",
    "      y_0: Tensor-like, with shape `y_shape`.\n",
    "      g: Scalar-like, as the gravitational constant, optional.\n",
    "      epsilon: Scalar-like, for numerical stability, optional.\n",
    "    Returns:\n",
    "      Scalar.\n",
    "    \"\"\"\n",
    "    with tf.name_scope(name, 'Action', [y, grad_y_bulk, y_0]):\n",
    "      y_bulk = tf.convert_to_tensor(y_bulk)\n",
    "      grad_y_bulk = tf.convert_to_tensor(grad_y_bulk)\n",
    "      y_0 = tf.convert_to_tensor(y_0)\n",
    "      # Add `batch_size`-dimension\n",
    "      y_0 = tf.expand_dims(y_0, axis=0)\n",
    "    \n",
    "      with tf.name_scope('DeltaHeight'):\n",
    "        delta_y = y_0 - y_bulk\n",
    "        # Clip `delta_y` so as to keep it positive\n",
    "        delta_y = tf.where(delta_y > 0.0, delta_y, tf.zeros_like(delta_y))\n",
    "        \n",
    "      with tf.name_scope('Lagrangian'):\n",
    "        lagrangians = tf.truediv(\n",
    "            tf.sqrt(1.0 + grad_y_bulk**2),\n",
    "            tf.sqrt(2.0 * g * delta_y) + epsilon)\n",
    "        \n",
    "      action = tf.reduce_mean(lagrangians)\n",
    "      return action\n",
    "\n",
    "\n",
    "def make_boundary(y_boundary, target_y_boundary, n=4, lambda_=10.0, name=None):\n",
    "  \"\"\"Make the boundary term, vanishing of which makes the fitting of boundary.\n",
    "  \n",
    "  $ b(y, y_b) := \\lambda * \\norm{y - y_b}_n $\n",
    "  \n",
    "  Args:\n",
    "    y_boundary: Tensor-like, with the shape `[n_boundary] + y_shape`, as the\n",
    "        boundary given by the neural network, as the $y$.\n",
    "    target_y_boundary: Tensor-like, with the shape `[n_boundary] + y_shape`,\n",
    "        as the target boundary to fit, as the $y_b$.\n",
    "    n: Positive integer, employ L-`n` norm.\n",
    "    lambda: Positive float.\n",
    "  Returns:\n",
    "    Scalar.\n",
    "  \"\"\"\n",
    "  with tf.name_scope(name, 'Boundary', [y_boundary, target_y_boundary]):\n",
    "    y_boundary = tf.convert_to_tensor(y_boundary)\n",
    "    target_y_boundary = tf.convert_to_tensor(target_y_boundary)\n",
    "    # `delta` shall be vanishing\n",
    "    delta = (y_boundary - target_y_boundary)\n",
    "    boundary = lambda_ * l_n_norm(delta, n)\n",
    "    return boundary\n",
    "\n",
    "\n",
    "def l_n_norm(x, n, name=None):\n",
    "  \"\"\"L-`n` norm of tensor `x`.\"\"\"\n",
    "  with tf.name_scope(name, 'L{}_Norm'.format(n), [x]):\n",
    "    x = tf.convert_to_tensor(x)\n",
    "    norm = tf.reduce_mean(x**n)\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ResultOps = namedtuple('ResultOps',\n",
    "    'loss, grad_y_bulk, y_bulk, y_boundary, action, boundary')\n",
    "\n",
    "\n",
    "def make_loss(x_bulk, x_boundary, target_y_boundary, make_y,\n",
    "              name=None):\n",
    "  \"\"\"Implements the loss.\n",
    "  \n",
    "  It is found that `loss = action * (1 + boundary)` is much more numerically\n",
    "  stable and performs much better than `loss = action + boundary`.\n",
    "  \n",
    "  XXX: Why so?\n",
    "  \n",
    "  Args:\n",
    "    x_bulk: Tensor-like, with shape `[batch_size] + x_shape`, as the\n",
    "        non-boundary values of the input to the neural network.\n",
    "    x_boundary: Tensor-like, with shape `[n_boundaries] + x_shape`, as\n",
    "        the boundary values of the input to the neural network.\n",
    "    target_y_boundary: Tensor-like, with the shape `[n_boundary] + y_shape`,\n",
    "        as the target boundary to fit.\n",
    "    make_y: Callable that maps `x` to the neural network output.\n",
    "  Returns:\n",
    "    Scalar.\n",
    "  \"\"\"\n",
    "  with tf.name_scope(name, 'Loss',\n",
    "        [x_bulk, x_boundary, target_y_boundary]):\n",
    "    x_bulk = tf.convert_to_tensor(x_bulk)\n",
    "    x_boundary = tf.convert_to_tensor(x_boundary)\n",
    "    target_y_boundary = tf.convert_to_tensor(target_y_boundary)\n",
    "    \n",
    "    x = tf.concat([x_bulk, x_boundary], axis=0)    \n",
    "    y = make_y(x)\n",
    "\n",
    "    batch_size = x_bulk.get_shape().as_list()[0]\n",
    "    n_boundary = x_boundary.get_shape().as_list()[0]\n",
    "    y_bulk, y_boundary = tf.split(y, [batch_size, n_boundary],\n",
    "                                  axis=0)\n",
    "    grad_y_bulk = tf.gradients(y_bulk, [x_bulk])[0]\n",
    "    y_0 = tf.unstack(target_y_boundary, axis=0)[0]\n",
    "\n",
    "    action = make_action(y_bulk, grad_y_bulk, y_0)\n",
    "    boundary = make_boundary(y_boundary, target_y_boundary)\n",
    "    loss = action * (1 + boundary)\n",
    "\n",
    "  return ResultOps(loss, grad_y_bulk, y_bulk, y_boundary, action, boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l1_norm(x):\n",
    "    \"\"\"L1-norm.\"\"\"\n",
    "    return np.mean(np.abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.16 s, sys: 10 ms, total: 3.17 s\n",
      "Wall time: 3.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x_dim = 1\n",
    "n_samples = 100\n",
    "y_dim = 1\n",
    "\n",
    "x_bulk = tf.placeholder(shape=[n_samples, x_dim], dtype='float32',\n",
    "                        name='x_bulk')\n",
    "x_boundary = np.array([[0.0], [3.0]], dtype='float32')\n",
    "target_y_boundary = np.array([[0.0], [-1.0]], dtype='float32')\n",
    "\n",
    "hidden_layers = []\n",
    "for i in range(5):\n",
    "    hidden_layers += [\n",
    "        lambda x: tf.layers.dense(\n",
    "            x, 10, activation=tf.nn.sigmoid),\n",
    "        lambda x: tf.layers.dropout(x),\n",
    "    ]\n",
    "        \n",
    "def make_y(x):\n",
    "    return make_neural_network(x, hidden_layers, [y_dim])\n",
    "\n",
    "ops = make_loss(x_bulk, x_boundary, target_y_boundary, make_y)\n",
    "\n",
    "# For optimizing\n",
    "optimizer = tf.train.AdamOptimizer(0.01)\n",
    "train_op = optimizer.minimize(ops.loss)\n",
    "\n",
    "# For logging\n",
    "tf.summary.scalar('loss', ops.loss)\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "sess_config = tf.ConfigProto(device_count={'GPU': 0})  # CPU only.\n",
    "sess = tf.Session(config=sess_config)\n",
    "\n",
    "# -- Initializing\n",
    "# For logging\n",
    "current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "writer = tf.summary.FileWriter('../dat/logdir/'+ current_time, sess.graph)\n",
    "# Initialize all `tf.Variable`s, explicit or implicit\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.266656 0.255405 0.0440526 0.288139 1.05377\n",
      "2000 0.270422 0.259624 0.0415879 0.300666 1.0794\n",
      "3000 0.285345 0.276613 0.031569 0.320508 0.997551\n",
      "4000 0.275951 0.268054 0.0294611 0.356027 0.999261\n",
      "5000 0.267021 0.257313 0.0377279 0.293182 1.05868\n",
      "6000 0.257481 0.244795 0.0518239 0.24173 1.08339\n",
      "7000 0.276747 0.267217 0.0356622 0.323406 1.0346\n",
      "8000 0.269339 0.253637 0.061909 0.292319 1.04626\n",
      "9000 0.265347 0.257874 0.0289788 0.274811 1.05872\n",
      "10000 0.266215 0.257482 0.0339172 0.291734 1.01964\n",
      "11000 0.275684 0.265649 0.0377743 0.339838 1.02664\n",
      "12000 0.256908 0.249721 0.0287797 0.251535 1.05984\n",
      "13000 0.272998 0.264662 0.0314959 0.325004 1.03875\n",
      "14000 0.267495 0.253286 0.0560985 0.284837 1.09851\n",
      "15000 0.287321 0.276491 0.0391711 0.37071 0.970534\n",
      "16000 0.262961 0.255718 0.0283254 0.304206 1.06018\n",
      "17000 0.256616 0.248626 0.0321366 0.253657 1.08373\n",
      "18000 0.257265 0.247593 0.039065 0.277762 1.06883\n",
      "19000 0.277573 0.269131 0.0313666 0.292857 0.999471\n",
      "20000 0.272149 0.260339 0.0453663 0.294444 1.04065\n",
      "21000 0.246597 0.236363 0.0432971 0.224966 1.09963\n",
      "22000 0.275841 0.263669 0.0461644 0.29757 1.03964\n",
      "23000 0.262965 0.252183 0.0427533 0.295454 1.01602\n",
      "24000 0.269634 0.260969 0.0332038 0.31028 1.00416\n",
      "25000 0.267193 0.258642 0.0330601 0.324683 1.04481\n",
      "26000 0.254835 0.245846 0.0365623 0.315496 1.13767\n",
      "27000 0.262998 0.252036 0.0434937 0.423246 1.18715\n",
      "28000 0.259174 0.248754 0.0418902 0.369058 1.18223\n",
      "29000 0.2649 0.255373 0.0373077 0.390487 1.1769\n",
      "30000 0.274585 0.26509 0.0358169 0.432282 1.05676\n",
      "31000 0.277263 0.267229 0.0375484 0.435236 1.07661\n",
      "32000 0.271547 0.260784 0.0412726 0.431903 1.13789\n",
      "33000 0.255461 0.245636 0.0400003 0.378947 1.15931\n",
      "34000 0.266593 0.258124 0.0328071 0.409565 1.16552\n",
      "35000 0.266901 0.257703 0.0356945 0.422404 1.1561\n",
      "36000 0.26872 0.258037 0.0414014 0.441986 1.08744\n",
      "37000 0.25196 0.241675 0.0425565 0.328025 1.16722\n",
      "38000 0.264703 0.252063 0.0501474 0.396829 1.12205\n",
      "39000 0.307097 0.293885 0.0449587 0.522065 1.0525\n",
      "40000 0.272539 0.260123 0.0477307 0.427771 1.13109\n"
     ]
    }
   ],
   "source": [
    "# -- Optimizing\n",
    "\n",
    "# Parameters\n",
    "n_iters = 4*10**4\n",
    "\n",
    "def get_x_bulk_value():\n",
    "    x_bulk_value = []\n",
    "    for i in range(n_samples):\n",
    "        x_i = [-np.random.uniform(-x_boundary[1,0], -x_boundary[0,0])]\n",
    "        x_bulk_value.append(x_i)\n",
    "    x_bulk_value = np.array(x_bulk_value, dtype='float32')\n",
    "    x_bulk_value = np.sort(x_bulk_value, axis=0)\n",
    "    return x_bulk_value\n",
    "\n",
    "# Iterations\n",
    "for i in range(n_iters):\n",
    "    step = i + 1\n",
    "    iter_ops = [train_op, summary_op, ops.loss, ops.y_bulk,\n",
    "                ops.grad_y_bulk, ops.action, ops.boundary]\n",
    "    x_bulk_value = get_x_bulk_value()\n",
    "    result = sess.run(iter_ops, feed_dict={x_bulk: x_bulk_value})\n",
    "    _, summary, loss, y, grad_y, action, boundary = result\n",
    "    \n",
    "    # For debugging\n",
    "    if np.isnan(loss):\n",
    "        print(step, loss, action, boundary, grad_y, x_bulk_value, y)\n",
    "        break\n",
    "\n",
    "    # Logging\n",
    "    if step % 1000 == 0:\n",
    "        writer.add_summary(summary, step)\n",
    "        print(step, loss, action, boundary,\n",
    "              l1_norm(grad_y), l1_norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3e54087c18>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8VdW99/HP72QkYQhkIIQkBEyYRYZAUdCioCJFEetY\ntVZ767VevbV9Wq+PtrX23qq3vfVe67W21mpp69Q6FAcUEaEoIhIGZQgY5iGBhGAGQuas548cfSgG\nEjhJ9hm+79frvDg5WZz1W24537PX3nttc84hIiKRx+d1ASIi4g0FgIhIhFIAiIhEKAWAiEiEUgCI\niEQoBYCISIRSAIiIRCgFgIhIhFIAiIhEqGivCziRlJQUl5OT43UZIiIhY/Xq1Qedc6kdaRvUAZCT\nk0NBQYHXZYiIhAwz29XRtpoCEhGJUAoAEZEIpQAQEYlQCgARkQilABARiVAKABGRCKUAEBGJUGEX\nAHWNzTy+bBvLtx70uhQRkaAWdgEQG+Xj8WU7eG7VHq9LEREJamEXAD6fMX14Gku3lNLY3OJ1OSIi\nQSvsAgBg+og0quuaWLXjkNeliIgErbAMgKl5KcRF+1hUeMDrUkREglZYBkBCbDRTc1N4u/AAzjmv\nyxERCUphGQAA00f0Z8+hWopKD3tdiohIUArjAEgDYNEmTQOJiLQlbAOgf+94xmT24W0dBxARaVPY\nBgDAjBH9WbengrLqeq9LEREJOmEfAM7Bks2lXpciIhJ0wjoARgzoxcCkHry1ab/XpYiIBJ2wDgAz\n44JR/VlWdJCa+iavyxERCSphHQAAM0el09DUwpItmgYSETla2AdAfk4/UnrG8uYGTQOJiBwtoAAw\ns35mtsjMivx/9j1B2ygzW2tmrwXS58mK8hnnj0xnyeZS6hqbu7NrEZGgFugewF3AYudcHrDY//Px\nfAcoDLC/U3LR6HRqGpp5r0j3CBAR+UygATAHmOd/Pg+4tK1GZpYJfAV4IsD+TsnkIcn0jo/mzY2a\nBhIR+UygAdDfOVfif74f6H+cdv8D3Al4skB/bLSPGSP6s2jTAd0jQETEr90AMLO3zWxDG485R7dz\nrctufmHpTTObDZQ651Z3pCAzu9nMCsysoKysrKPjaNfM0elU1jaycrvuESAiAhDdXgPn3Izj/c7M\nDpjZAOdciZkNANo613IKcImZzQLigd5m9mfn3HXH6e9x4HGA/Pz8TlvL+ZyhqSTERvHGhhKm5qV0\n1tuKiISsQKeAXgFu8D+/AZh/bAPn3P91zmU653KAq4F3jvfh35XiY6I4d3gab27YT5OmgUREAg6A\nB4HzzawImOH/GTPLMLMFgRbX2S4ek0F5TQMrtpd7XYqIiOfanQI6EedcOTC9jdeLgVltvL4UWBpI\nn4GYNiyVnnHRvPpRMWfnpXpVhohIUAj7K4GPFh8TxQWj+vPmhv00NGkaSEQiW0QFALROA1XVNfFu\nUeedYSQiEooiLgCm5KaQlBDDqx8Ve12KiIinIi4AYqN9XDQ6nUWbDlDboLWBRCRyRVwAAMwek0FN\nQ7OWiBaRiBaRATB5SDIpPeM0DSQiES0iAyDKZ8weM4DFm0upPNLodTkiIp6IyAAA+Or4TBqaWnh9\nfUn7jUVEwlDEBsDogb3JTevJy2v3el2KiIgnIjYAzIzLxg9k1c5P2VVe43U5IiLdLmIDAODSsQMx\ng5fX7vO6FBGRbhfRAZCR1IMzhyTz8tp9tN7OQEQkckR0AABcNj6TXeVHWLP7U69LERHpVhEfADNH\npxMf4+OlNZoGEpHIEvEB0DMumpmj0nnlo2LqGrU0hIhEjogPAIArJ2ZRXdfEGxt0TYCIRA4FADB5\ncDKDkhN4ftUer0sREek2CgDA5zOuzM/ig+2H2HFQ1wSISGRQAPhdPiETn8FfCrQXICKRQQHg1793\nPOcNT+OF1XtpatbtIkUk/CkAjnLVxGzKqutZskW3ixSR8KcAOMq5w1JJ7RXH86t2e12KiEiXUwAc\nJTrKxxUTMnlncynFFbVelyMi0qUUAMe4ZlI2Dnj2Q+0FiEh4UwAcI6tfAtOHp/Hsh3toaNLBYBEJ\nXwqANlw3eRAHD9fz5sb9XpciItJlFABtOCcvlUHJCfx5xS6vSxER6TIKgDb4fMZ1XxrEhzsPsXl/\nldfliIh0CQXAcVw+IZO4aB9/0l6AiISpgALAzPqZ2SIzK/L/2fc47ZLM7AUz22xmhWZ2ZiD9doe+\nibFcfEYGL6/dR2Vto9fliIh0ukD3AO4CFjvn8oDF/p/b8jDwpnNuOHAGUBhgv93iG2flcKShWReG\niUhYCjQA5gDz/M/nAZce28DM+gDnAL8HcM41OOcqAuy3W4we2IcvDe7HvPd3aX0gEQk7gQZAf+fc\nZ3dR2Q/0b6PNYKAMeMrM1prZE2aWeLw3NLObzazAzArKyrxfk+ebUwezr6JWp4SKSNhpNwDM7G0z\n29DGY87R7ZxzDnBtvEU0MB54zDk3Dqjh+FNFOOced87lO+fyU1NTT240XWD6iP4MSk7g9+/t8LoU\nEZFO1W4AOOdmOOdGt/GYDxwwswEA/j9L23iLvcBe59xK/88v0BoIISHKZ9w0ZTBrd1ewZvenXpcj\nItJpAp0CegW4wf/8BmD+sQ2cc/uBPWY2zP/SdGBTgP12q8snZNI7Plp7ASISVgINgAeB882sCJjh\n/xkzyzCzBUe1ux142sw+BsYC9wfYb7dKjIvmmknZvLlhP3sOHfG6HBGRThFQADjnyp1z051zef6p\nokP+14udc7OOarfOP68/xjl3qXMu5OZSbpwyGJ/BE+9u97oUEZFOoSuBOyi9Tzxzxw3kuVV7OHi4\n3utyREQCpgA4CTefcxoNzS3Me3+n16WIiARMAXASctN6cuHIdOa9v5PD9U1elyMiEhAFwEm6Zdpp\nVNU18exKLQ8hIqFNAXCSxmYlcdZpyTzx3nbqm5q9LkdE5JQpAE7BrdNyOVBVz18K9npdiojIKVMA\nnIIpuclMGNSXx5Zs1V6AiIQsBcApMDO+Mz2P4so6XlitvQARCU0KgFN0dl4K47KT+PWSbTQ0aalo\nEQk9CoBTZGbcMWMo+ypqtRcgIiFJARCAc/JSGJuVxKNLtmovQERCjgIgAK17AXnsq6jlLwV7vC5H\nROSkKAAC9OWhqUzM6cuvFhdR26AzgkQkdCgAAmRm3DlzOKXV9cxbsdPrckREOkwB0Akm5vTj3GGp\nPLZ0G5W1jV6XIyLSIQqATvL9C4dRWdvI75bpfgEiEhoUAJ1kVEYfLj4jgyeX76CsWvcLEJHgpwDo\nRN87fygNTS38z9ufeF2KiEi7FACdaHBKItdNHsRzq/ZQdKDa63JERE5IAdDJ/nV6HgmxUTzwxmav\nSxEROSEFQCfrlxjLbefm8s7mUpZvPeh1OSIix6UA6AI3nJXDwKQe/Oz1QppbnNfliIi0SQHQBeJj\norhz5jA2lVTxohaKE5EgpQDoIpeckcH47CR+vnAzVXW6OExEgo8CoIuYGfddMprymgZ+9XaR1+WI\niHyBAqALnZ7Zh6snZvGH93eytVSnhYpIcFEAdLHvXzCMhNgofvLKJpzTAWERCR4KgC6W3DOO750/\nlPe2HmThxv1elyMi8jkFQDe4bvIghqf34r5XN1FT3+R1OSIiQIABYGb9zGyRmRX5/+x7nHbfNbON\nZrbBzJ41s/hA+g010VE+fjb3dEoq6/jvRVonSESCQ6B7AHcBi51zecBi/8//wMwGAv8K5DvnRgNR\nwNUB9htyJgzqyzWTsnnq/Z1sLK70uhwRkYADYA4wz/98HnDpcdpFAz3MLBpIAIoD7Dck/dvMYST1\niOGelzfQoiuERcRjgQZAf+dcif/5fqD/sQ2cc/uA/wJ2AyVApXPureO9oZndbGYFZlZQVlYWYHnB\nJSkhlnu+MoJ1eyp4+sPdXpcjIhGu3QAws7f9c/fHPuYc3c61nuP4ha+1/uMCc4DBQAaQaGbXHa8/\n59zjzrl851x+amrqSQ8o2M0dN5Apucn85xubKa6o9bocEYlg7QaAc26Gc250G4/5wAEzGwDg/7O0\njbeYAexwzpU55xqBl4CzOnMQocTMeGDuGJpbHD/82wZdGyAingl0CugV4Ab/8xuA+W202Q1MNrME\nMzNgOlAYYL8hLTs5ge9fOIx3Npcyf11EHg4RkSAQaAA8CJxvZkW0ftN/EMDMMsxsAYBzbiXwArAG\nWO/v8/EA+w153zgrh/HZSdz36kYOHtY9hEWk+1kwT0Hk5+e7goICr8voMltLq5n18HvMGJnGo18b\nT+sOkojIqTOz1c65/I601ZXAHspN68Ud5+exYP1+XvlIU0Ei0r0UAB7753NOY3x2Ej+ev5EDVXVe\nlyMiEUQB4LEon/HLK8dS39TMnS98rLOCRKTbKACCwOCURP7vRSP4+ydlPKMLxESkmygAgsT1kwcx\nNTeF/3itkG1lh70uR0QigAIgSPh8xn9dcQZxMT7ueG4dDU0tXpckImFOARBE0vvE859fHcP6fZX8\nctEWr8sRkTCnAAgyF45K52tfyubxZdtZvvWg1+WISBhTAAShH31lJENSEvnu8+t0lbCIdBkFQBDq\nERvF/35tPJW1jXz3+XW6d4CIdAkFQJAaMaA39148ineLDvLY37d5XY6IhCEFQBC7ZlIWF5+RwS/f\n2sKHOw55XY6IhBkFQBAzM+6fO5pByYnc9swayqp1PEBEOo8CIMj1io/h19eOp6qukdueWUNTs64P\nEJHOoQAIASMG9Ob+uaezcschfr5Q1weISOdQAISIy8Zncv3kQTy+bDtvrC/xuhwRCQMKgBDyo9kj\nGZedxPf/+hGfHKj2uhwRCXEKgBASG+3jsWsnkBAXzbf+WEDFkQavSxKREKYACDHpfeL5zXUTKKmo\n4/Zn1+qgsIicMgVACJowqC//fmnrRWIPvrHZ63JEJERFe12AnJqrJmazqbiKJ97bwdD0XlyZn+V1\nSSISYrQHEMJ+OHskU3NTuOfl9azcXu51OSISYhQAISwmysej144nq18Ct/x5NbvKa7wuSURCiAIg\nxPXpEcOTN0zEAd+cV0DlkUavSxKREKEACAM5KYn85roJ7Cqv4ZY/r9btJEWkQxQAYWLykGR+fvkY\nVmwv564XP8Y53UNARE5MZwGFkbnjMtlzqJaHFn1CZr8Evnf+UK9LEpEgpgAIM7efl8ueQ0f41eIi\nBibFc9XEbK9LEpEgFdAUkJldYWYbzazFzPJP0G6mmW0xs61mdlcgfcqJmRn3X3Y65wxN5e6XN/DO\n5gNelyQiQSrQYwAbgMuAZcdrYGZRwKPARcBI4BozGxlgv3ICMVE+Hrt2PCMH9ObWp9ewdvenXpck\nIkEooABwzhU659pboH4SsNU5t9051wA8B8wJpF9pX2JcNE9+YyL9e8dz0x9Wsa3ssNcliUiQ6Y6z\ngAYCe476ea//Neliqb3imHfjJKJ8xtd//yEllbVelyQiQaTdADCzt81sQxuPLvkWb2Y3m1mBmRWU\nlZV1RRcRJSclkT/cOImq2kau//2HfFqjJaRFpFW7AeCcm+GcG93GY34H+9gHHL1SWab/teP197hz\nLt85l5+amtrBLuRERg/sw+9uyGf3oSPc+IdV1NQ3eV2SiASB7pgCWgXkmdlgM4sFrgZe6YZ+5SiT\nhyTzv9eMY/2+Sm7+UwF1jc1elyQiHgv0NNC5ZrYXOBN43cwW+l/PMLMFAM65JuA2YCFQCPzFObcx\nsLLlVFwwKp1fXD6G5VvLue2ZtTTqZjIiEc2CecmA/Px8V1BQ4HUZYedPK3byo/kbmTM2g4euHEuU\nz7wuSUQ6iZmtds4d97qso+lK4Ah0/Zk5VNc38fM3t9AjJor7556OTyEgEnEUABHq1mm51DY088g7\nW4mL9vGTS0ZhphAQiSQKgAj2vfOHUtfYzO/e3UFstI+7Z41QCIhEEAVABDMz7p41gvqmFn737g5i\nonz84MJhCgGRCKEAiHBmxk8uHkVjs+PXS7fhM+P/XDBUISASARQAgs9n/OzS0Tjn+N8lWzFrnR5S\nCIiENwWAAK0hcP/c03EOHnlnK6AQEAl3CgD5nM9nPHDZ6UBrCDS3OB0TEAljCgD5B5+FgM9n/Hrp\nNppbHHddNFwhIBKGFADyBZ8dE4j2Gb9dtp36phbuvXikQkAkzCgApE0+n/HTOaOIjjKeWr6T+qZm\n/uPS07VshEgYUQDIcZkZP549koTYKB5dso3ahmb+64oziI7qjkVkRaSrKQDkhMyMH1w4nITYaH6x\ncAu1jc386ppxxEVHeV2aiARIX+WkQ/7l3FzuvXgkCzce4CbdVEYkLCgApMNunDKYX15xBh9sP8S1\nT6yk4ohuLykSyhQAclK+OiGTx64dz6biKq74zQqKK3SjeZFQpQCQk3bBqHTm3TSJ/ZV1fPWx9yk6\nUO11SSJyChQAckrOPC2Z5/55Mk0tjst/s4LVuw55XZKInCQFgJyyURl9eOnbZ9EvMZav/W4lb24o\n8bokETkJCgAJSFa/BF645UxGZvTm20+v4cn3dnhdkoh0kAJAApbcM45n/mkyF4zsz09f28R9r26k\nucV5XZaItEMBIJ2iR2wUv752AjdOyeGp5Tu5+Y8FHNa1AiJBTQEgnSbKZ9x78Sh+OmcUSz8p02mi\nIkFOASCd7utn5vDkNyay99AR5jy6nNW7PvW6JBFpgwJAusSXh6by4q1nkRAbxTWPf8BfC/Z4XZKI\nHEMBIF1maP9ezP+XKUwa3I8fvPAx9726kcbmFq/LEhE/BYB0qaSEWP5w48TPDw5f+8RKSqvrvC5L\nRFAASDeIjvJx78Wj+O+rzuDjvRVc/Mh7unJYpA3NLY7nV+3mnpfXd0t/CgDpNnPHZfLyrVOIj4ni\nqt9+wBPvbsc5XS8gArBq5yHmPPoe//bierbsr6a2obnL+wwoAMzsCjPbaGYtZpZ/nDZZZrbEzDb5\n234nkD4ltI0Y0JtXbpvK9BFp/MfrhXzrj6u1rLREtOKKWm5/di1X/GYF5YcbePjqsfz1ljPpEdv1\nN12yQL6BmdkIoAX4LfB951xBG20GAAOcc2vMrBewGrjUObepvffPz893BQVfeEsJA845nlq+kwfe\nKCStVzwPXz2W/Jx+Xpcl0m3qGpt54t3tPLpkGy3O8c/nDOGWaaeREBvYjRrNbLVzrs0v5McKqCfn\nXKG/wxO1KQFK/M+rzawQGAi0GwASvsyMm6YOZvygvtz+7Bqu/O0Kbj8vj9vPy9U9hyWsOedYtOkA\n//76JvYcquWi0encPWsEWf0Sur2Wbr0nsJnlAOOAld3ZrwSvsVlJLPjXs7l3/kYeXlzEe1sP8t9X\njiU7ufv/MYh0te1lh7nv1U38/ZMy8tJ68vQ/fYkpuSme1dNuAJjZ20B6G7+6xzk3v6MdmVlP4EXg\nDudc1Qna3QzcDJCdnd3Rt5cQ1is+hoeuGsuXh6Xyw5c3MPPhZdzzlRF8bVL2CfcuRULF4fomHnmn\niCff20F8dBQ/mj2Sr585iBiP93YDOgbw+ZuYLeU4xwD8v48BXgMWOuce6uj76hhA5NlXUcudL3zE\n8q3lfHloKg9+9XQG9OnhdVkip8Q5x/x1xdy/oJDS6nqumJDJnTOHk9orrsv6PJljAF0eP9b6Fe73\nQOHJfPhLZBqY1IM/3fQl7rtkFCt3lHPBQ8t4ZuVuWrS8tISYTcVVXPXbD7jj+XX07x3PS7eexS+u\nOKNLP/xPVqBnAc0FHgFSgQpgnXPuQjPLAJ5wzs0ys6nAu8B6Ws8YArjbObegvffXHkBk21Vew10v\nrmfF9nImD+nHA5eNYXBKotdliZxQxZEGHlr0CX/+YBdJCbH84MJhXJmfRZSve6YzT2YPoFOmgLqK\nAkCcczy/ag8/W1BIfWML3552Gt+edhrxMV1/jrTIyWhucTzz4W5++dYWqmobuX7yIL53/jD6JMR0\nax3ddhqoSFczM66elM15w1svHHt4cRHz1+3jJ5eMYtqwNK/LEwFgxbZyfvraJgpLqpg8pB8/uWQU\nw9N7e11Wu7QHICHl3aIyfjx/IzsO1jBjRBo//MpIcjQtJB7Zc+gID7xRyIL1+xmY1IO7Z41g1unp\nnp69pikgCWv1Tc08tXwnjywuorHZceOUHG49N5c+Pbp3V1siV3VdI48t3cYT7+0gyoxbp53Gt84Z\nEhRTkwoAiQilVXX855tbeGntXpJ6xHD7eXlcN3kQsdG6kli6RlNzC38p2MtDi7Zw8HADl40byA9m\nDguqU5UVABJRNhZXcv+CQpZvLSerXw/umD6US8cN7LazLiT8Oed4Z3MpD76xmaLSw0zM6cuPZo9k\nTGaS16V9gQJAIo5zjr9/UsYvFm5hY3EVuWk9+e6MoVw0Oh2fgkACsG5PBQ++UcgH2w8xOCWRf5s5\njAtHeTvPfyIKAIlYLS2ONzfu55dvbWFbWQ15aT257bxcZo/J0B6BnJStpdX8YuEWFm48QHJiLN+Z\nkcc1k7I9X76hPQoAiXjNLY7X15fwyOIiikoPMzglkW+dPYTLxg8MigN1Erx2HqzhV+8U8be1+0iI\njebmc4Zw09TB9IwLjbPmFQAifp/tETy2dBvr91WS0jOOG6fkcM2kbPolxnpdngSR3eVHeHTJVl5Y\ns5eYKOP6yYP49rTckPv/RAEgcgznHCu2lfPY37fxbtFB4qJ9zB03kG9MyQmJC3ak62wtPcyvl25l\n/rpionzG1yZlc+u5p5HWK97r0k6JrgQWOYaZcVZuCmflpvDJgWqeWr6Tl9bs5blVe5iY05frJg9i\n5uh04qI1PRQpPtpTwePLtrNgQwlx0T6+cVYON58zhP69Q/OD/1RoD0Ai1qc1Dfx19R6eXrmbXeVH\n6JsQw9xxmVw5MVN7BWGqpcWx9JNSfrdsByu2l9MrPprrJg/im1MHk9IzeFbpDISmgEROQkuL472t\nB3l+1R7e2rSfxmbHmMw+zB03kNljMoJq+V45NYfrm3hx9V7+8P5OdhysIb13PN+cOpirJ2XRKz68\nriBXAIicokM1Dfxt7T5eWL2XTSVVRPmMqbkpzB4zgAtGpWu5iRBTWFLFnz/Yxd/W7qOmoZmxWUnc\nOCWHWacPCPrTOU+VAkCkE3xyoJq/rd3H/HXF7KuoJSbKODsvlZmj0pk+Io3kMJkyCDdVdY289lEJ\nf129h7W7K4iL9jF7TAbXTc5mXHZfr8vrcgoAkU7knOOjvZW8/nExC9bvZ19FLT6D/Jx+TB+exnnD\n08hN6xm0V4ZGgoamFt4tKmP+umIWbtxPfVMLQ/v35Mr8LC6fkElSQmidyhkIBYBIF3HOsbG4irc2\n7uetTQfYvL8agKx+PTgnL5Wz81I487QUTRV1g4amFlZsL+fNDSW8sWE/FUcaSUqIYfaYAVwxIYsx\nmX0iMpQVACLdpLiiliVbSlmyuYwV2w5S09CMz+D0gX2YfFoyZw5JJj+nX8hcRRrsKmsbWfZJGe9s\nLmVx4QGq6ppIjI1i+oj+XDoug6m5qRG/GqwCQMQDjc0trN1dwbtFZazYVs5HeytobHb4DEZm9CZ/\nUD/GD+rLuKwkMvv2iMhvpyerqbmFj/dVsrzoIO9uPcjqXZ/S3OLomxDDecP7c9HodKbmpWh5j6Mo\nAESCwJGGJlbv+pRVOz+lYOch1u6uoLaxGYCUnrGMyUxidEZvRg/sw6iBfcjoEx/xoVDX2Mz6fZV8\nuOMQq3YeYvXOT6mub8IMRg7ozbRhqZw3PI2xWX21uN9x6EpgkSCQEBvN2XmpnJ2XCrTuIWzZX83a\nPRWs213B+n0VLN1SSov/O1jv+GiGD+jNiPRe5PbvRV5aT3LTepKcGBuWwVDX2Mzm/dVsKq5iY3El\n6/ZUsGV/NU3+/yC5aT2ZfUYGU3KTOeu0lJBbkycUaA9AxENHGpooLKliU0k1hSVVFJZUUXTgMIfr\nmz5v0ys+miEpieSkJJLVN4Hsfglk9utBRp8epPeJD+rpj5YWx8HD9ewsP8LO8hp2HKyh6MBhtpUd\nZld5zefh1ys+mjMykzgjqw9js/oyYVBffeCfIk0BiYQw5xz7q+r45MBhtpcdZsfBms8fJZV1NLf8\n47/Z5MRY+veOJ613HGm94kjuGUdyYiz9EmNJSoihT4/WR8+4GBLjokiMjT7lm+Q456hvauFwfROH\n65qorG3k0yMNfHqkgfLDDZRV11NaXc+BqjqKK2oprqyjoanl878f7TMGpySS178nuWm9GDmgN6My\neuuYSCfSFJBICDMzBvTpwYA+Pfjy0NR/+F1TcwsllXXsOXSE4srWD9mSylpKq1o/eDcVV3GopuHz\naZTjiY32ER/tIz4mipgoH9FRRrTP8Pk/hB2t396bWhxNzS00NLdQ29BMXVPLFwLo2PdN69UaRKdn\nJnHh6HgGJvVgUHIiOckJZCT1CNsrcEORAkAkhERH+cjql0BWv4TjtnHOUVXXxKGaBiprG6k40vpn\nTX0zNfVNVNc3Ud/YTF1jM3WNLa0f8i0tNDU7HP//w91nRkyUjyifERvto0dMFPExPhJio+kVH03P\nuGh6x8fQNzGWvgkxJCfG0btHtL7JhxAFgEiYMbPPp31ETkT7YiIiEUoBICISoRQAIiIRKqAAMLMr\nzGyjmbWY2QlPOzKzKDNba2avBdKniIh0jkD3ADYAlwHLOtD2O0BhgP2JiEgnCSgAnHOFzrkt7bUz\ns0zgK8ATgfQnIiKdp7uOAfwPcCfQ0l5DERHpHu1eB2BmbwPpbfzqHufc/A78/dlAqXNutZlN60D7\nm4GbAbKzs9trLiIip6hT1gIys6XA951zX1i4x8weAK4HmoB4oDfwknPuug68bxmw6xTLSgEOnuLf\nDTbhMpZwGQdoLMEoXMYBgY1lkHMutf1m3RAAx7Sb5m83O+BO26+poKMLIgW7cBlLuIwDNJZgFC7j\ngO4bS6Cngc41s73AmcDrZrbQ/3qGmS3ojAJFRKRrBLQWkHPuZeDlNl4vBma18fpSYGkgfYqISOcI\n5yuBH/e6gE4ULmMJl3GAxhKMwmUc0E1jCeobwoiISNcJ5z0AERE5gZAOADObaWZbzGyrmd3Vxu/N\nzH7l//2srdDVAAAC60lEQVTHZjbeizo7ogNjmWZmlWa2zv/4sRd1tsfMnjSzUjPbcJzfh9I2aW8s\nobJNssxsiZlt8q/d9Z022oTEdungWEJlu8Sb2Ydm9pF/LPe10aZrt4tzLiQfQBSwDRgCxAIfASOP\naTMLeAMwYDKw0uu6AxjLNOA1r2vtwFjOAcYDG47z+5DYJh0cS6hskwHAeP/zXsAnIfxvpSNjCZXt\nYkBP//MYYCUwuTu3SyjvAUwCtjrntjvnGoDngDnHtJkD/NG1+gBIMrMB3V1oB3RkLCHBObcMOHSC\nJqGyTToylpDgnCtxzq3xP6+mdVHGgcc0C4nt0sGxhAT/f+vD/h9j/I9jD8p26XYJ5QAYCOw56ue9\nfPF/hI60CQYdrfMs/27gG2Y2qntK63Shsk06KqS2iZnlAONo/bZ5tJDbLicYC4TIdvEvk78OKAUW\nOee6dbvonsChYw2Q7Zw7bGazgL8BeR7XFOlCapuYWU/gReAO51yV1/UEop2xhMx2cc41A2PNLAl4\n2cxGO+faPObUFUJ5D2AfkHXUz5n+1062TTBot07nXNVnu4vOuQVAjJmldF+JnSZUtkm7QmmbmFkM\nrR+YTzvnXmqjSchsl/bGEkrb5TPOuQpgCTDzmF916XYJ5QBYBeSZ2WAziwWuBl45ps0rwNf9R9In\nA5XOuZLuLrQD2h2LmaWbmfmfT6J125V3e6WBC5Vt0q5Q2Sb+Gn8PFDrnHjpOs5DYLh0ZSwhtl1T/\nN3/MrAdwPrD5mGZdul1CdgrIOddkZrcBC2k9i+ZJ59xGM7vF//vfAAtoPYq+FTgC3OhVvSfSwbFc\nDnzbzJqAWuBq5z9NIJiY2bO0noWRYq3rRN1L68GtkNom0KGxhMQ2AabQuiLvev98M8DdQDaE3Hbp\nyFhCZbsMAOaZWRStIfUX59xr3fkZpiuBRUQiVChPAYmISAAUACIiEUoBICISoRQAIiIRSgEgIhKh\nFAAiIhFKASAiEqEUACIiEer/Adck0ZFUBfAaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3ebc3815c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Return the predict-values of the trained neural network\n",
    "x_bulk_value = np.linspace(x_boundary[0,0], x_boundary[1,0],\n",
    "                           n_samples, dtype='float32')\n",
    "x_bulk_value = np.expand_dims(x_bulk_value, axis=1)\n",
    "y_bulk_value = sess.run(\n",
    "    ops.y_bulk,\n",
    "    feed_dict={x_bulk: x_bulk_value})\n",
    "\n",
    "# Visualization\n",
    "plt.plot(x_bulk_value, y_bulk_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "  * Compare with analytic result.\n",
    "  * Coherent the numerical stability at boundary and the penalty to the boundary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
